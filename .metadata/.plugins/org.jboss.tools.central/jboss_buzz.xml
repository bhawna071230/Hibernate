<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">Kafka Monitoring Dashboards with Business Central</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/K6YHkmYZsOo/kafka-monitoring-dashboards-from-business-central.html" /><author><name>William Siqueira</name></author><id>https://blog.kie.org/2021/05/kafka-monitoring-dashboards-from-business-central.html</id><updated>2021-05-07T18:41:36Z</updated><content type="html">Kafka is one of the major platforms for async communication in cloud computing and jBPM has a nice with it, making it part of a business process. In real-world projects, monitoring the Kafka queues used by jBPM can help you to identify process bottlenecks. Previously we talked about in Business Central via DashBuilder, and today we will show how to monitor Kafka queues from jBPM using a Kafka Data Set which is included by Business Central 7.52.0 and onwards. KAFKA DATA SETS The first step to build a dashboard is having data sets. To retrieve information from Kafka, Business Central needs to invoke Kafka “mbeans” and all the metrics are identified after the MBeans names. (for more information, check the about how to monitor Kafka installations) Having this said, bear in mind that the metrics are a snapshot of the Kafka status, because it does not accumulate value. For this purpose, users must set up an agent in Kafka and store the metrics in a system like Prometheus for cumulative and historical values. Business Central supports 3 types of Kafka data sets: * BROKER: When using Broker you will be monitoring Kafka server metrics, general metrics; * CONSUMER: To monitor consumers and messages handled by a consumer; * PRODUCER: To monitor producers and messages created by a producer. The common parameters for all types are: * Name: Give the data set a name; * Host: The host where Kafka component (BROKER,CONSUMER or PRODUCER) is running; * Port: The JMX port. When making Kafka available for monitoring you must set a JMX port; * Target: Select the target installation type: BROKER, CONSUMER, PRODUCER; * Filter: Any text used to filter the result, this way we can create data sets focused on a specific set of results. It is a “LIKE” operation, which means that it only shows results that contain the text in the filter The properties above are all you need to create BROKER metrics. When you select CONSUMER or PRODUCER then there are other possible parameters: * ClientID: This is a mandatory field for CONSUMER and PRODUCER, it identifies the client ID; * NodeID: The node id is an optional parameter to identify a node from which we want metrics from; * TopicID: The topic id is an optional parameter used to identify a topic from which we want metrics from. To create a Kafka Data Set, log in Business Central, go to Admin -&gt; Data Sets, click on “New Data Set” and select Kafka from the list: Now, you can fill the required fields and test the data set. After a successful test, you can go back to the setup screen to add a filter if necessary. KAFKA MONITORING DASHBOARD Now that we know about Kafka data sets let’s create a simple Dashboard. First, make sure you downloaded Kafka locally. Using Docker is possible but you must make sure that JMX ports are exposed. 1. Download Kafka 2. Start Zookeeper in a console ./bin/zookeeper-server-start.sh config/zookeeper.properties 3. In a new console start Kafka (Broker) — before export JMX_PORT=9999 export JMX_PORT=9999 ./bin/kafka-server-start.sh config/server.properties 4. Create the topic using some console window ./bin/kafka-topics.sh — create — topic example-topic — bootstrap-server localhost:9092 — replication-factor 1 — partitions 1 5. In a new console start a Consumer — export JMX_PORT=9998 export JMX_PORT=9998 ./bin/kafka-console-consumer.sh — group dashbuilder_test — topic example-topic — bootstrap-server localhost:9092 6. In a new console start the Producer export JMX_PORT=9997 ./bin/kafka-console-producer.sh — topic example-topic — broker-list localhost:9092 In the producer window, you can type the text that will be received by the consumer. We are done on the Kafka side, now let’s create the required data sets in Business Central. Let’s create three of them, one for each type using the following parameters. Host: localhost Port: 9999 for broker — 9998 for consumer and 9997 for producer Client ID: console-producer for producer or consumer-dashbuilder_test-1 for consumer Topic: example-topic BROKER: BROKER OUTPUT: CONSUMER: CONSUMER OUTPUT PRODUCER: PRODUCER OUTPUT: With these 3 data sets, we can now monitor the topic “example-topic” and query everything about the broker. In Business Central you can now create dashboards using the data sets we created: * Go to Design -&gt; Pages and create a new Page * Drag the Table Reporting component to the page and select any of the Kafka data sets Since each metric is a data set row, to show a specific attribute we can also filter the data set when building the data set, here’s an example to show specifically the number of records for the producer: Users can decide to create specific data sets for the wanted attributes using the filter field or create a data set with all attributes and filters when creating the dashboard. If you followed the steps above to set up Kafka you can import the in and it should work. CONCLUSION In this post, we show how to create Kafka data sets and Dashboards in Business Central and how to import it in Dashbuilder Runtime. With this new feature, we can monitor all the parts of a business process when it uses Kafka to identify bottlenecks or simply monitor any Kafka installation from Business Central. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/K6YHkmYZsOo" height="1" width="1" alt=""/&gt;</content><dc:creator>William Siqueira</dc:creator><feedburner:origLink>https://blog.kie.org/2021/05/kafka-monitoring-dashboards-from-business-central.html</feedburner:origLink></entry><entry><title type="html">Infinispan 12.1.2.Final</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/kAc0iUombkc/infinispan-12-1-2-final" /><author><name>Katia Aresti</name></author><id>https://infinispan.org/blog/2021/05/07/infinispan-12-1-2-final</id><updated>2021-05-07T12:00:00Z</updated><content type="html">Dear Infinispan community, It’s been a month since our first 12.1.0.Final release and we already released two additional minors with some bug fixes and upgrades. The latest version is 12.1.2.Final. Highlights of Infinispan 12.1.1 and 12.1.2 include: * Grafana Dashboards for the Operator . * Performance regression fix . * Index and Query statistics improved in the Infinispan Web Console . * Several component upgrades * Documentation enchancements You can find release notes for both versions at: and&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/kAc0iUombkc" height="1" width="1" alt=""/&gt;</content><dc:creator>Katia Aresti</dc:creator><feedburner:origLink>https://infinispan.org/blog/2021/05/07/infinispan-12-1-2-final</feedburner:origLink></entry><entry><title>Report from the virtual ISO C++ meetings in 2020 (core language)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/K9K7zXVNh9U/" /><category term="C" /><category term="Linux" /><category term="Open source" /><category term="Programming Languages" /><category term="C++ standard" /><category term="gcc" /><category term="ISO C++" /><author><name>Jason Merrill</name></author><id>https://developers.redhat.com/blog/?p=849117</id><updated>2021-05-07T07:00:48Z</updated><published>2021-05-07T07:00:48Z</published><content type="html">&lt;p&gt;C++ standardization was dramatically different in 2020 from earlier years. The business of the International Organization for Standardization (ISO) committee all took place virtually, much like everything else during this pandemic. This article summarizes the &lt;a target="_blank" rel="nofollow" href="/topics/c"&gt;C++&lt;/a&gt; standardization proposals before the Core and Evolution Working Groups last year.&lt;/p&gt; &lt;h2&gt;Core language&lt;/h2&gt; &lt;p&gt;The C++ Core Working Group (CWG) had already been holding monthly Zoom teleconferences between meetings; this was how I encountered Zoom in the before times. So the transition for us was fairly smooth.&lt;/p&gt; &lt;p&gt;We did end up moving a few papers at a virtual full committee plenary on one of the days of the canceled November meeting.&lt;/p&gt; &lt;h3&gt;Literal suffix for (signed) size_t&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p0330"&gt;P0330&lt;/a&gt;) was ready after the Belfast meeting in November 2019, but because it was intended as a C++23 feature, we didn&amp;#8217;t want to bring it up for a vote until after we finished C++20. This proposal makes it easier to write a constant of &lt;code&gt;size_t&lt;/code&gt; or &lt;code&gt;ptrdiff_t&lt;/code&gt; type. This practice is useful, for instance, to match the return type of a &lt;code&gt;size()&lt;/code&gt; function:&lt;/p&gt; &lt;pre&gt;auto m = std::max (0, v.size()); // error, deduction mismatch int vs. size_t auto m = std::max (0uz, v.size()); // OK, both arguments are size_t&lt;/pre&gt; &lt;p&gt;Earlier versions of this proposal used &lt;code&gt;t&lt;/code&gt; for &lt;code&gt;ptrdiff_t&lt;/code&gt; and &lt;code&gt;z&lt;/code&gt; for &lt;code&gt;size_t&lt;/code&gt;, like the &lt;code&gt;printf&lt;/code&gt; conversion specifiers, but the final version uses &lt;code&gt;uz&lt;/code&gt; for &lt;code&gt;size_t&lt;/code&gt; and &lt;code&gt;z&lt;/code&gt; for the corresponding signed type (usually the same as &lt;code&gt;ptrdiff_t&lt;/code&gt;).&lt;/p&gt; &lt;h3&gt;Numeric and universal character escapes in character and string literals&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2029"&gt;P2029&lt;/a&gt;) clarifies the handling of hex and octal character escapes to standardize the GNU Compiler Collection (GCC) behavior rather than the (Microsoft Visual C++) MSVC behavior: Namely, that a single escape code can correspond to a single UTF-8 code unit, not necessarily an entire character.&lt;/p&gt; &lt;pre&gt;constexpr const char8_t c[] = u8"\xc3\x80"; // UTF-8 encoding of U+00C0 {LATIN CAPITAL LETTER A WITH GRAVE}&lt;/pre&gt; &lt;h3&gt;Declarations and where to find them&lt;/h3&gt; &lt;p&gt;During the week of the planned June meeting, CWG decided to meet for the full week, two hours a day, to continue reviewing a paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p1787"&gt;P1787&lt;/a&gt;) we had started to look at in Prague: An ambitious proposal to overhaul the wording for declaration scope and name lookup completely, and thereby fix more than 60 open issues. One week stretched into three before we got through the whole paper.&lt;/p&gt; &lt;p&gt;This paper&amp;#8217;s changes should not affect a significant amount of code; many changes are clarifications that bring the wording in line with existing practice. Some are clarifications of corner cases that most code doesn&amp;#8217;t depend on, such as ambiguous lookup within a &lt;em&gt;conversion-type-id&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;A few changes allow code that was previously ill-formed:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;em&gt;conversion-type-id&lt;/em&gt; is added to the list of type-only contexts from &lt;a target="_blank" rel="nofollow" href="http://wg21.link/p0634"&gt;P0634&lt;/a&gt;: &lt;pre&gt;template &amp;#60;class T&amp;#62; struct A { operator T::type(); }; // OK&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;&lt;code&gt;::template&lt;/code&gt; is also not required in type-only contexts: &lt;pre&gt;template &amp;#60;class T&amp;#62; auto f(T t) { return static_cast&amp;#60;T::X&amp;#60;int&amp;#62;&amp;#62;(t); } // OK&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Default template arguments are now complete-class contexts, like default function arguments: &lt;pre&gt;template &amp;#60;class T&amp;#62; struct A { template &amp;#60;int I = sizeof(t)&amp;#62; void g() { } // OK T t; };&lt;/pre&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;One change might break a small amount of existing code: Because the lookup for a name after a dot (.) or arrow operator (-&amp;#62;) now happens first in the scope of the object, &lt;code&gt;.template&lt;/code&gt; is required in &lt;code&gt;&lt;em&gt;dependent&lt;/em&gt;.template X&amp;#60;...&amp;#62;&lt;/code&gt; even if a definition of X would be found by  an unqualified lookup:&lt;/p&gt; &lt;pre&gt;template &amp;#60;int&amp;#62; struct X { void f(); }; template &amp;#60;class T&amp;#62; void g(T t) { t.X&amp;#60;2&amp;#62;::f(); } // error, needs .template&lt;/pre&gt; &lt;h3&gt;Generalized wording for partial specializations&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2096"&gt;P2096&lt;/a&gt;) just cleaned up places in the standard that still referred to partial specializations only for classes, so that these places cover variable partial specializations, as well.&lt;/p&gt; &lt;h3&gt;Down with ()!&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p1102"&gt;P1102&lt;/a&gt;) has completed its Core review and should be ready for a vote at the next virtual plenary. The paper proposes a change to lambda syntax to avoid requiring () in a mutable lambda:&lt;/p&gt; &lt;pre&gt;[x = 42] () mutable { ++x; }; // () are uselessly required in C++20&lt;/pre&gt; &lt;h2&gt;Language evolution&lt;/h2&gt; &lt;p&gt;The C++ Evolution Working Group (EWG) has been meeting regularly to discuss future directions, but as a matter of policy, has not been voting to forward papers to the CWG until a face-to-face meeting takes place.  Recently, they decided on electronic voting, and the following papers were up for EWG voting through February.&lt;/p&gt; &lt;h3&gt;Narrowing contextual conversions to bool&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="http://wg21.link/cwg2039"&gt;CWG2039&lt;/a&gt; changed the condition of a &lt;code&gt;static_assert&lt;/code&gt; to reject narrowing conversions to &lt;code&gt;bool&lt;/code&gt;, for instance, from integers larger than 1. This seems to have been unintended, and most compilers haven&amp;#8217;t implemented it yet. So this paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p1401"&gt;P1401&lt;/a&gt;) changes the feature back and makes the same change to the condition of &lt;code&gt;if constexpr&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;static_assert (2, "two"); // OK again&lt;/pre&gt; &lt;h3&gt;Make declaration order layout mandated&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p1847"&gt;P1847&lt;/a&gt;) argues that because no compiler actually reorders data members with different access, we should drop that permission.&lt;/p&gt; &lt;h3&gt;if consteval&lt;/h3&gt; &lt;p&gt;This proposed mechanism (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p1938"&gt;P1938&lt;/a&gt;) is much like &lt;code&gt;if (std::is_constant_evaluated())&lt;/code&gt;, except that the first block of the &lt;code&gt;if&lt;/code&gt; is an immediate function context, allowing calls to &lt;code&gt;consteval&lt;/code&gt; functions with arguments that depend on the parameters of the current (&lt;code&gt;constexpr&lt;/code&gt;) function.&lt;/p&gt; &lt;h3&gt;C++ identifier syntax using Unicode standard annex 31&lt;/h3&gt; &lt;p&gt;C++ has periodically needed to change its list of Unicode characters that are allowed in identifiers; this paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p1949"&gt;P1949&lt;/a&gt;) proposes adopting the set specified by the actual Unicode standard, which has stabilized since C++11.&lt;/p&gt; &lt;h3&gt;Freestanding optional operator new&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2013"&gt;P2013&lt;/a&gt;) proposes that a freestanding implementation need not provide a definition of the replaceable &lt;code&gt;new&lt;/code&gt; operator.&lt;/p&gt; &lt;h3&gt;Allow duplicate attributes&lt;/h3&gt; &lt;p&gt;C++11 attributes disallowed the repetition of the same attribute within a single attribute list, like &lt;code&gt;[[nodiscard, nodiscard]]&lt;/code&gt;. C recently removed this restriction, and this paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2156"&gt;P2156&lt;/a&gt;) proposes to do the same for C++.&lt;/p&gt; &lt;h3&gt;Attributes on lambda-expressions&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2173"&gt;P2173&lt;/a&gt;) proposes allowing attributes to appear in a lambda after the lambda-introducer, such as:&lt;/p&gt; &lt;pre&gt;[] [[nodiscard]] (int x) { return x; }&lt;/pre&gt; &lt;h3&gt;Removing garbage collection support&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2186"&gt;P2186&lt;/a&gt;) points out that there are no implementations of the C++11 &amp;#8220;minimal support for garbage collection,&amp;#8221; and that several C++ implementations of actual garbage collection don&amp;#8217;t interact with the C++11 feature, and so proposes removing it.&lt;/p&gt; &lt;h3&gt;Mixed string literal concatenation&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2201"&gt;P2201&lt;/a&gt;) proposes changing the concatenation of string literals with different encoding prefixes from conditionally supported to ill-formed.&lt;/p&gt; &lt;h3&gt;Trimming whitespaces before line splicing&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2223"&gt;P2223&lt;/a&gt;) proposes ignoring any whitespace after a backslash (\) at the end of a line, except in a raw string.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The various working groups continued to meet virtually through the beginning of the year, and had another virtual plenary the week of the originally planned February meeting.  Currently the tentative plan is to continue meeting virtually through the end of 2021 and meet in person again in February 2022.&lt;/p&gt; &lt;p&gt;For more information on C and C++, please visit &lt;a target="_blank" rel="nofollow" href="/topics/c"&gt;Red Hat Developer&amp;#8217;s topic page&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#38;linkname=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#38;linkname=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#38;linkname=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#38;linkname=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#38;linkname=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#38;linkname=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#38;linkname=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#038;title=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" data-a2a-url="https://developers.redhat.com/blog/2021/05/07/report-from-the-virtual-iso-c-meetings-in-2020-core-language/" data-a2a-title="Report from the virtual ISO C++ meetings in 2020 (core language)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/07/report-from-the-virtual-iso-c-meetings-in-2020-core-language/"&gt;Report from the virtual ISO C++ meetings in 2020 (core language)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/K9K7zXVNh9U" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;C++ standardization was dramatically different in 2020 from earlier years. The business of the International Organization for Standardization (ISO) committee all took place virtually, much like everything else during this pandemic. This article summarizes the C++ standardization proposals before the Core and Evolution Working Groups last year. Core language The C++ Core Working Group (CWG) [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/07/report-from-the-virtual-iso-c-meetings-in-2020-core-language/"&gt;Report from the virtual ISO C++ meetings in 2020 (core language)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/05/07/report-from-the-virtual-iso-c-meetings-in-2020-core-language/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">849117</post-id><dc:creator>Jason Merrill</dc:creator><dc:date>2021-05-07T07:00:48Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/05/07/report-from-the-virtual-iso-c-meetings-in-2020-core-language/</feedburner:origLink></entry><entry><title>Use multiple compilers to build better projects</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/xXslsKHu7G0/" /><category term="C" /><category term="clang/LLVM" /><category term="Linux" /><category term="Performance" /><category term="C/C++ compilers" /><category term="CI pipelines" /><category term="debugging" /><category term="gcc" /><author><name>Timm Baeder</name></author><id>https://developers.redhat.com/blog/?p=896297</id><updated>2021-05-07T07:00:28Z</updated><published>2021-05-07T07:00:28Z</published><content type="html">&lt;p&gt;For a multitude of reasons, developers usually compile the project they are working on with only one compiler. On &lt;a target="_blank" rel="nofollow" href="/products/rhel/overview"&gt;Red Hat Enterprise Linux 8&lt;/a&gt;, the system compiler for &lt;a target="_blank" rel="nofollow" href="/topics/c"&gt;C and C++&lt;/a&gt; is GNU Compiler Collection (GCC) 8, and newer versions are available through the GCC toolset.&lt;/p&gt; &lt;p&gt;However, there are several reasons why you might also build your project with &lt;a target="_blank" rel="nofollow" href="https://clang.llvm.org/"&gt;Clang&lt;/a&gt;. Red Hat Enterprise Linux 8 offers the &lt;a target="_blank" rel="nofollow" href="https://llvm.org/"&gt;LLVM&lt;/a&gt; toolset, which contains &lt;a target="_blank" rel="nofollow" href="/blog/category/clang-llvm/"&gt;Clang&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;In this article, we&amp;#8217;ll take a look at why one might use more than one compiler. We&amp;#8217;ll focus on a system where GCC is currently the default compiler and consider Clang as the main alternative.&lt;/p&gt; &lt;h2&gt;Detecting compiler-specific behavior&lt;/h2&gt; &lt;p&gt;When you try to compile a project with a compiler not usually used by the project, one of the most frequent problems is the project&amp;#8217;s assumptions about the compiler in use. These assumptions can appear in many places within a project, from command-line options to supported features to compiler extensions.&lt;/p&gt; &lt;p&gt;Generally, all of those compiler-specific features are to be avoided, unless the project explicitly supports only compilers that offer nonstandard features. If you depend on a particular compiler or nonstandard features, that dependency should be documented in the project&amp;#8217;s build documentation and ideally enforced by the build system.&lt;/p&gt; &lt;p&gt;To ensure that a project keeps building with other compilers, it is useful to regularly build it with a new compiler. Such a build can also detect implementation-defined behavior, undefined behavior, and (in rare cases) compiler bugs.&lt;/p&gt; &lt;p&gt;Other potential problems include differences in supported &lt;code&gt;__attribute__((foo))&lt;/code&gt; directives (or &lt;code&gt;[[attribute-name]]&lt;/code&gt; for C++), differences in supported language standards, and the use of unimplemented compiler built-ins.&lt;/p&gt; &lt;h2&gt;Getting different error messages from multiple compilers&lt;/h2&gt; &lt;p&gt;One of the biggest benefits of using a modern compiler is the warnings and error messages it generates, based on the command-line options the developers pass. Fixing these warnings can result in better code quality, increased portability, and fewer bugs.&lt;/p&gt; &lt;p&gt;One common problem is that not all compilers accept the same command-line arguments, so projects have to check for them at configure time. Depending on the needs of the project, most end up maintaining a list of compiler options for each compiler they build with.&lt;/p&gt; &lt;p&gt;Because figuring out whether a compiler supports a command-line option is so common, the usual build systems have built-in ways of performing these checks.&lt;/p&gt; &lt;p&gt;CMake uses the &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://cmake.org/cmake/help/v3.14/module/CheckCCompilerFlag.html"&gt;check_c_compiler_flag()&lt;/a&gt;&lt;/code&gt; or &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://cmake.org/cmake/help/latest/module/CheckCXXCompilerFlag.html"&gt;check_cxx_compiler_flag()&lt;/a&gt;&lt;/code&gt; functions:&lt;/p&gt; &lt;pre&gt;include(CheckCCompilerFlag) check_c_compiler_flag("-Werror=header-guard", CC_SUPPORTS_HEADER_GUARD) check_c_compiler_flag("-Werror=logical-op", CC_SUPPORTS_LOGICAL_OP) &lt;/pre&gt; &lt;p&gt;Meson uses the &lt;code&gt;get_supported_arguments()&lt;/code&gt; function of the compiler object:&lt;/p&gt; &lt;pre&gt;test_cflags = [    '-Werror=header-guard',    '-Werror=logical-op' ] cc = meson.get_compiler('c') supported_flags = cc.get_supported_arguments(test_cflags) &lt;/pre&gt; &lt;p&gt;There are many more build systems, of course, but they all provide a more-or-less elegant way of dealing with this issue.&lt;/p&gt; &lt;p&gt;So, having configured our build with checks for compiler options, we can have a successful build with both Clang and GCC, or potentially any other compiler.&lt;/p&gt; &lt;p&gt;The following code shows an error when built with GCC, using the &lt;code&gt;-Wlogical-op&lt;/code&gt; command-line option. Clang does not support that option and remains silent about the suspicious use of logical operators:&lt;/p&gt; &lt;pre&gt;int main(int argc, char **argv) { if (argc &amp;#62; 0 &amp;#38;&amp;#38; argc &amp;#62; 0) {      return 1;    }    return 0; } &lt;/pre&gt; &lt;p&gt;GCC 10&amp;#8217;s output with &lt;code&gt;-Wlogical-op&lt;/code&gt; looks like this:&lt;/p&gt; &lt;pre&gt;test.c: In function ‘main’: test.c:2:16: warning: logical ‘and’ of equal expressions [-Wlogical-op] 2 | if (argc &amp;#62; 0 &amp;#38;&amp;#38; argc &amp;#62; 0) { | ~~~~~~~~~^~~~~~~~~~~ &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: See this code on &lt;a target="_blank" rel="nofollow" href="https://godbolt.org/z/Mz191P4oc"&gt;godbolt.org&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;As already mentioned, Clang ignores this (potential) problem. But if we include the following header file in our previous test, GCC will remain silent about the typo in the header guard, while Clang will helpfully point out the mistake. Header guards like this are still relatively common in both C and C++ code, and the problem is usually hard to find:&lt;/p&gt; &lt;pre&gt;#ifndef __TEST_HEADER_H__ #define __TEST_HEADRE_H__ /* ... Code ...*/ #endif &lt;/pre&gt; &lt;p&gt;Clang with the &lt;code&gt;-Werror=header-guard&lt;/code&gt; option tells us about the broken header guard:&lt;/p&gt; &lt;pre&gt;In file included from test.c:3: ./test.h:1:9: error: '__TEST_HEADER_H__' is used as a header guard here, followed by #define of a different macro [-Werror,-Wheader-guard] #ifndef __TEST_HEADER_H__         ^~~~~~~~~~~~~~~~~ ./test.h:2:9: note: '__TEST_HEADRE_H__' is defined here; did you mean '__TEST_HEADER_H__'? #define __TEST_HEADRE_H__         ^~~~~~~~~~~~~~~~~         __TEST_HEADER_H__ &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: See this code on &lt;a target="_blank" rel="nofollow" href="https://godbolt.org/z/87668f1sE"&gt;godbolt.org&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;GCC is unable to detect this problem. The examples of different behavior I&amp;#8217;ve shown in this section are just two of many examples one could find.&lt;/p&gt; &lt;p&gt;In practice, if the compilers emit only warnings and not errors, their usefulness depends on a developer actually looking at the compiler output. Passing &lt;code&gt;-Werror&lt;/code&gt; to the compiler during development is also useful because it makes the compiler treat all warnings as errors.&lt;/p&gt; &lt;h2&gt;Static analysis&lt;/h2&gt; &lt;p&gt;One particularly well-known part of Clang is the &lt;a target="_blank" rel="nofollow" href="https://clang-analyzer.llvm.org/"&gt;static analyzer&lt;/a&gt;. Static analysis can be used to analyze certain aspects of a program &amp;#8220;statically,&amp;#8221; meaning, before runtime. This allows for more thorough checking because the time taken by the analyzer is not as important as the time taken by the compiler.&lt;/p&gt; &lt;p&gt;Because it does not need manual intervention, static analysis is particularly useful in &lt;a target="_blank" rel="nofollow" href="/topics/ci-cd"&gt;continuous integration (CI)&lt;/a&gt;, where we can use it for every push to a repository. However, it is usually hard to keep code 100% clean of reports from the static analyzer. This is partly due to how thorough static analyzers are: They find many problems that compilers don&amp;#8217;t find, but some of these are false positives, caused by implicit invariants the analyzer doesn&amp;#8217;t know about. Encoding these assumptions in the form of assertions usually improves code clarity and also makes the analyzer happy.&lt;/p&gt; &lt;h2&gt;Sanitizers&lt;/h2&gt; &lt;p&gt;Clang comes with a couple of &lt;i&gt;sanitizers&lt;/i&gt;, which instrument the compiled program at runtime. Sanitizers are usually used for issues that would otherwise require developers to rerun the program and get information about the problematic behavior, which costs additional time. They are also used for issues that don&amp;#8217;t abort the program but cause problems later on, such as integer overflows or access to uninitialized data.&lt;/p&gt; &lt;p&gt;The most useful and common sanitizers supported in Clang are the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://clang.llvm.org/docs/AddressSanitizer.html"&gt;AddressSanitizer&lt;/a&gt; can be used to detect various memory problems such as null pointer dereferences, use-after-free, and double/invalid free. It can be enabled via &lt;code&gt;-fsanitize=address&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://clang.llvm.org/docs/MemorySanitizer.html"&gt;MemorySanitizer&lt;/a&gt; can be used to detect access to uninitialized memory. It can be enabled via &lt;code&gt;-fsanitize=memory&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://clang.llvm.org/docs/ThreadSanitizer.html"&gt;ThreadSanitizer&lt;/a&gt; detects data races in multithreaded programs. It can be enabled via &lt;code&gt;-fsanitize=thread&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html"&gt;UndefinedBehaviorSanitizer&lt;/a&gt; detects various kinds of undefined behavior. It can be enabled via &lt;code&gt;-fsanitize=undefined&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;GCC supports all these sanitizers except for the memory sanitizer. These are the big sanitizers, but both GCC and Clang support many &lt;a target="_blank" rel="nofollow" href="https://clang.llvm.org/docs/UsersManual.html#controlling-code-generation"&gt;more fine-grained&lt;/a&gt; checks, so it might be worth checking their documentation for useful sanitizers and their options.&lt;/p&gt; &lt;p&gt;If the software has a test suite (which it should), and that test suite is run in a continuous integration fashion (which it should be), compiling the test suite with some of the sanitizers mentioned in this section makes a lot of sense and does not increase run time as much as running the programs in Valgrind would.&lt;/p&gt; &lt;p&gt;It is, however, certainly also helpful if developers have one or another sanitizer enabled when working on the software itself on a daily basis, to catch errors with real-world data as soon as possible.&lt;/p&gt; &lt;p&gt;For a more in-depth introduction to sanitizers and a comparison to the super useful Valgrind tool, check out &lt;a target="_blank" rel="nofollow" href="/blog/2021/05/05/memory-error-checking-in-c-and-c-comparing-sanitizers-and-valgrind/"&gt;Jan Kratochvil&amp;#8217;s recent article on the topic&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Clang fuzzer&lt;/h2&gt; &lt;p&gt;A &lt;em&gt;fuzzer&lt;/em&gt; is a tool that generates random input for a library under test. Fuzz testing is useful to find errors and crashes in any sort of file parser. Clang contains &lt;a target="_blank" rel="nofollow" href="https://llvm.org/docs/LibFuzzer.html"&gt;libFuzzer&lt;/a&gt;, which can be used for this sort of testing.&lt;/p&gt; &lt;p&gt;The fuzzer will keep providing new input to the library under test until a bug is found, so in the best case, the run of the fuzzer program continues for an indefinite amount of time. This case of fuzzing cannot be used in an automated fashion, but is still very valuable for developers to use manually.&lt;/p&gt; &lt;p&gt;For an introduction to using Clang&amp;#8217;s fuzzer on RHEL with llvm-toolset, read &lt;a target="_blank" rel="nofollow" href="/blog/2019/03/05/introduction-to-using-libfuzzer-with-llvm-toolset/"&gt;this article&lt;/a&gt; by Tom Stellard.&lt;/p&gt; &lt;h2&gt;Link-time optimized (LTO) builds&lt;/h2&gt; &lt;p&gt;More and more distributions are switching to using link-time optimized (LTO) builds. In these builds, the compiler does not emit native object code, but its intermediate representation (IR). The IR is then handed to the linker, which can apply intermodular optimizations.&lt;/p&gt; &lt;p&gt;LTO also helps identify issues with symbol visibility by removing symbols that are unused and not explicitly marked as externally visible. This can help you avoid accidentally exporting symbols that are not meant for public consumption.&lt;/p&gt; &lt;p&gt;Both GCC and LLVM support LTO builds, as well as a couple of configuration options to fit the needs of different use cases. For more details on these options as well as the inner working of the compilers during LTO builds, consult the &lt;a target="_blank" rel="nofollow" href="https://gcc.gnu.org/onlinedocs/gccint/LTO-Overview.html"&gt;GCC&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://llvm.org/docs/LinkTimeOptimization.html"&gt;LLVM&lt;/a&gt; documentation regarding this topic.&lt;/p&gt; &lt;h2&gt;Control flow integrity in Clang&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://clang.llvm.org/docs/ControlFlowIntegrity.html"&gt;Clang&amp;#8217;s control flow integrity (CFI)&lt;/a&gt; is a special type of sanitizer that requires link-time optimization (LTO) to be used. You can enable it via &lt;code&gt;-fsanitize=cfi&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;CFI allows instrumentation of the compiled program to detect certain forms of undefined behavior and to abort the program in these cases. The CFI sanitizer supports different schemes, and they are usually optimized enough so that they can be enabled even in release builds. Google, for example, is known to do this &lt;a target="_blank" rel="nofollow" href="https://source.android.com/devices/tech/debug/cfi"&gt;on Android&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This is an example of security hardening that is available only on Clang right now.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Different compilers come with their strengths and weaknesses. Testing your project with different compilers will ensure you do not rely on particular compiler-specific behaviors—or even bugs. Many open source projects already have a CI pipeline that leverages more than one compiler, configuration, or platform. That is ideal, and you should try to do this for all of your projects if it makes sense for them. If you can&amp;#8217;t, it makes sense to at least use another compiler once in a while, or try to integrate this practice into your local development workflow.&lt;/p&gt; &lt;p&gt;Using sanitizers in your test suite and static analyzers regularly (or even via a special build in CI) is a great way of finding bugs ahead of time. Again, different tools show different defects in your code. Carefully evaluating them pays off in the long run. Try out other tools and use the one you feel most comfortable with on a daily basis. But always keep other options in mind and automate what you can.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#38;linkname=Use%20multiple%20compilers%20to%20build%20better%20projects" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#38;linkname=Use%20multiple%20compilers%20to%20build%20better%20projects" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#38;linkname=Use%20multiple%20compilers%20to%20build%20better%20projects" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#38;linkname=Use%20multiple%20compilers%20to%20build%20better%20projects" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#38;linkname=Use%20multiple%20compilers%20to%20build%20better%20projects" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#38;linkname=Use%20multiple%20compilers%20to%20build%20better%20projects" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#38;linkname=Use%20multiple%20compilers%20to%20build%20better%20projects" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#038;title=Use%20multiple%20compilers%20to%20build%20better%20projects" data-a2a-url="https://developers.redhat.com/blog/2021/05/07/use-multiple-compilers-to-build-better-projects/" data-a2a-title="Use multiple compilers to build better projects"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/07/use-multiple-compilers-to-build-better-projects/"&gt;Use multiple compilers to build better projects&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/xXslsKHu7G0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;For a multitude of reasons, developers usually compile the project they are working on with only one compiler. On Red Hat Enterprise Linux 8, the system compiler for C and C++ is GNU Compiler Collection (GCC) 8, and newer versions are available through the GCC toolset. However, there are several reasons why you might also [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/07/use-multiple-compilers-to-build-better-projects/"&gt;Use multiple compilers to build better projects&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/05/07/use-multiple-compilers-to-build-better-projects/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">896297</post-id><dc:creator>Timm Baeder</dc:creator><dc:date>2021-05-07T07:00:28Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/05/07/use-multiple-compilers-to-build-better-projects/</feedburner:origLink></entry><entry><title type="html">Kogito Tooling 0.9.1 Released!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/MBQsIdkStb4/kogito-tooling-0-9-1-released.html" /><author><name>Eder Ignatowicz</name></author><id>https://blog.kie.org/2021/05/kogito-tooling-0-9-1-released.html</id><updated>2021-05-07T05:00:00Z</updated><content type="html">We have just launched a fresh new Kogito Tooling release! &#x1f389; On the 0.9.1 , we made a lot of improvements and bug fixes. We are also happy to announce the MVP of our DMN Runner and many enhancements on Custom Task support on BPMN. This post will give a quick overview of this release and add some highlights of our release. I hope you enjoy it! CUSTOM TASK SUPPORT ENHANCEMENT ON BPMN We made many improvements regarding custom task support on BPMN, especially related to compatibility with Business Central projects. Stay tuned that soon we will publish a blog post with a deep dive into these enhancements. BPMN EDITOR – READ-ONLY MODE We introduced read-only mode support for our BPMN Editors. This feature is handy when you embed our editors using our . Simple pass ‘readOnly:true’ in our editor startup to activate this mode (it also works for DMN). You can also see this new mode in action in our : AUGMENTING THE DEVELOPER EXPERIENCE WITH DMN RUNNER We’ve been exploring ways to augment the developer experience for the Business Modeler Editors. In the spirit of “release early, release often” and MVPs, we’d like to share an early stage of a running prototype of the DMN Runner so that we can gather more feedback. You can watch the presentation of this prototype in or try it out in our environment. Soon we will publish a post with more details. NEW FEATURES, FIXED ISSUES, AND IMPROVEMENTS We also made some new features, a lot of refactorings and improvements, with highlights to: * – [BPMN] Reuse Data Types across the process * – SceSim runner does not display reason for failure * – [Scesim Editor] Bottom scroll bar getting hide * – [DMN Designer] Multiple DRDs support – The undo/redo are lost when the user changes between diagrams * – Unable to view service tasks in VSCode on windows * – Standalone editors setContent implementation should receive path and content * – [DMN Designer] Error during the save/marshaller of specific diagrams * – [DMN Designer] Decision Service is missing inputData element in model with multiple DRDs FURTHER READING/WATCHING We had some cool talks recently at the KIE youtube channel: * Augmenting the developer experience with DMN Runner, by Eder; * LACE Score Demonstration with DMN, by Rachid; * A chat about Open Source, leadership, and communities with Mark Proctor I would like to also recommend the recent article from . He provides a complete step-by-step tutorial to use Test Scenario Editor to test your DMN assets on VS Code and also, this from Guilherme where he details how the new Feel code completion works under the hood. THANK YOU TO EVERYONE INVOLVED! I would like to thank everyone involved with this release, from the excellent KIE Tooling Engineers to the lifesavers QEs and the UX people that help us look awesome! The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/MBQsIdkStb4" height="1" width="1" alt=""/&gt;</content><dc:creator>Eder Ignatowicz</dc:creator><feedburner:origLink>https://blog.kie.org/2021/05/kogito-tooling-0-9-1-released.html</feedburner:origLink></entry><entry><title>Why Windows and Linux line endings don’t line up (and how to fix it)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/pDUESnapAjw/" /><category term=".NET" /><category term="Kubernetes" /><category term="Linux" /><category term="Windows" /><category term="Linux line endings" /><category term="Windows in containers" /><category term="Windows line endings" /><author><name>Don Schenck</name></author><id>https://developers.redhat.com/blog/?p=894667</id><updated>2021-05-06T07:00:54Z</updated><published>2021-05-06T07:00:54Z</published><content type="html">&lt;p&gt;I recently wrote a few automated database-populating scripts. Specifically, I am running Microsoft SQL Server in a container in a Kubernetes cluster—okay, it&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;, but it&amp;#8217;s still &lt;a target="_blank" rel="nofollow" href="/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. It was all fun and games until I started mixing &lt;a target="_blank" rel="nofollow" href="/blog/category/windows/"&gt;Windows&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="/topics/linux"&gt;Linux&lt;/a&gt;; I was developing on my Windows machine, but obviously the container is running Linux. That&amp;#8217;s when I got the gem of an error shown in Figure 1. Well, not so much an error as errant output.&lt;/p&gt; &lt;div id="attachment_894697" style="width: 386px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/crlf_errant_output.png"&gt;&lt;img aria-describedby="caption-attachment-894697" class="wp-image-894697 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/crlf_errant_output.png" alt="Weird line endings in SQL statement output." width="376" height="258" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/crlf_errant_output.png 376w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/crlf_errant_output-300x206.png 300w" sizes="(max-width: 376px) 100vw, 376px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-894697" class="wp-caption-text"&gt;Figure 1: Errant output from an SQL statement.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;span id="more-894667"&gt;&lt;/span&gt;What in the world? Here&amp;#8217;s the CSV data I used to populate the table:&lt;/p&gt; &lt;pre&gt;1,Active 2,Inactive 3,Ordered 4,Billed 5,Shipped &lt;/pre&gt; &lt;p&gt;Here&amp;#8217;s the T-SQL code I used for the same purpose:&lt;/p&gt; &lt;pre&gt;BULK INSERT dbo.StatusCodes FROM '/tmp/StatusCodes.csv' WITH (FORMAT='CSV',FIELDTERMINATOR=',',KEEPIDENTITY); GO SELECT * FROM dbo.StatusCodes; GO &lt;/pre&gt; &lt;p&gt;What is going on here?&lt;/p&gt; &lt;h2&gt;TL;DR: Line endings&lt;/h2&gt; &lt;p&gt;It&amp;#8217;s the line endings. They are the issue.&lt;/p&gt; &lt;p&gt;Specifically, Windows and Linux handle line endings differently. To understand why, we need to go back a ways in history.&lt;/p&gt; &lt;h2&gt;ASDFJKL&lt;/h2&gt; &lt;p&gt;Ever use a manual typewriter? Okay, okay &amp;#8230; enough of the &amp;#8220;That&amp;#8217;s old!&amp;#8221; jokes. Figure 2 illustrates.&lt;/p&gt; &lt;div id="attachment_894797" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a target="_blank" rel="nofollow" href="https://pixabay.com/photos/typewriter-isolated-nostalgic-old-1138293/"&gt;&lt;img aria-describedby="caption-attachment-894797" class="wp-image-894797" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/typewriter-1138293_640-300x218.png" alt="A photograph of a manual typewriter. Image by Gerhard G. on Pixabay." width="500" height="364" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/typewriter-1138293_640-300x218.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/typewriter-1138293_640.png 640w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-894797" class="wp-caption-text"&gt;Figure 2: What a manual typewriter looks like.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The typewriter mechanism that holds the rubber cylinder is called the &lt;em&gt;carriage&lt;/em&gt; because it carries the paper. (That rubber cylinder is technically known as a &lt;em&gt;platen&lt;/em&gt;, but stay with me as I employ poetic license and use &amp;#8220;carriage.&amp;#8221;)&lt;/p&gt; &lt;p&gt;As you type, the carriage moves to the left. When you reach the edge of the paper, you use the big lever on the far left to return the carriage to the starting position; that is, you perform a &lt;em&gt;carriage return&lt;/em&gt;. In addition, as the lever moves, it advances the paper up one line, which is known as a &lt;em&gt;line feed&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;When you do both movements, you get &amp;#8220;carriage return plus line feed,&amp;#8221; sometimes abbreviated to CRLF or CR/LF. You &lt;em&gt;can&lt;/em&gt; move the carriage without feeding one line, and you &lt;em&gt;can&lt;/em&gt; advance one line without moving the carriage. They are two distinct and separate actions, but anyone who has mastered the manual typewriter knows that they are typically done in one, swift, soulful, and athletic motion, akin to desktop gymnastics of the highest order. (Please excuse more poetic license as I romanticize about typing.)&lt;/p&gt; &lt;h2&gt;Teletype&lt;/h2&gt; &lt;p&gt;Meanwhile, over in the world of automation, the Teletype machine became very popular. This allowed the transmission of text around the world, across telephone lines. But long distance calls were expensive, so minimizing the time and data sent was paramount. So, it was decided that one and only one character would be used for a carriage return and line feed, the so-called &lt;em&gt;new line character&lt;/em&gt;. You see it as &amp;#8220;&lt;code&gt;\n&lt;/code&gt;&amp;#8221; in code. You paid for every byte, back then, so cutting costs was important.&lt;/p&gt; &lt;p&gt;We&amp;#8217;re talking about 300 baud modems here, folks. Just think about that; 300 bits per second; &lt;em&gt;three hundred&lt;/em&gt;. Now, we want gigabits everywhere.&lt;/p&gt; &lt;h2&gt;Back to line endings&lt;/h2&gt; &lt;p&gt;The reasons don&amp;#8217;t matter: Windows chose the CR/LF model, while Linux uses the &lt;code&gt;\n&lt;/code&gt; model. So, when you create a file on one system and use it on the other, hilarity ensues. Or, in this case, two hours of debugging ending in madness and me contemplating a new career in woodworking.&lt;/p&gt; &lt;h2&gt;Quick fix for Linux and Windows line endings&lt;/h2&gt; &lt;p&gt;The quick fix for those incompatible line endings was very simple: I altered my T-SQL to include the ROWTERMINATOR specification, like this:&lt;/p&gt; &lt;pre&gt;BULK INSERT dbo.StatusCodes FROM '/tmp/StatusCodes.csv' WITH (FORMAT='CSV',FIELDTERMINATOR=',',ROWTERMINATOR = '\r\n',KEEPIDENTITY); GO SELECT * FROM dbo.StatusCodes; GO &lt;/pre&gt; &lt;p&gt;That works when uploading my CSV from my Windows machine. When uploading from my Linux machine, I use the following, where the ROWTERMINATOR is the simple new line character:&lt;/p&gt; &lt;pre&gt;BULK INSERT dbo.StatusCodes FROM '/tmp/StatusCodes.csv' WITH (FORMAT='CSV',FIELDTERMINATOR=',',ROWTERMINATOR = '\n',KEEPIDENTITY); GO SELECT * FROM dbo.StatusCodes; GO &lt;/pre&gt; &lt;p&gt;Simple, but unless you know about it, you either get weird results or some seemingly unrelated error messages. So, be advised. For example, if I try to use the Windows-specific command (where ROWTERMINATOR is &amp;#8220;&lt;code&gt;\r\n&lt;/code&gt;&amp;#8220;) in my Linux environment, I get the following error:&lt;/p&gt; &lt;pre&gt;Msg 4879, Level 16, State 1, Server mssql-1-h2c96, Line 2 Bulk load failed due to invalid column value in CSV data file /tmp/StatusCodes.csv in row 1, column 2. Msg 7399, Level 16, State 1, Server mssql-1-h2c96, Line 2 The OLE DB provider "BULK" for linked server "(null)" reported an error. The provider did not give any information about the error. Msg 7330, Level 16, State 2, Server mssql-1-h2c96, Line 2 Cannot fetch a row from OLE DB provider "BULK" for linked server "(null)". Id statusCodeDescription ----------- --------------------- &lt;/pre&gt; &lt;h2&gt;What does it all mean?&lt;/h2&gt; &lt;p&gt;The upshot is this: You might see some hiccups and weird behavior when you use a file in both Windows and Linux. Just be aware of it and you&amp;#8217;ll be fine.&lt;/p&gt; &lt;p&gt;Visit my GitHub repository &lt;a target="_blank" rel="nofollow" href="https://github.com/donschenck/netcandystore"&gt;NetCandyStore&lt;/a&gt; for all of the code referenced in this article.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#38;linkname=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#38;linkname=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#38;linkname=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#38;linkname=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#38;linkname=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#38;linkname=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#38;linkname=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#038;title=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" data-a2a-url="https://developers.redhat.com/blog/2021/05/06/why-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it/" data-a2a-title="Why Windows and Linux line endings don’t line up (and how to fix it)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/06/why-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it/"&gt;Why Windows and Linux line endings don&amp;#8217;t line up (and how to fix it)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/pDUESnapAjw" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;I recently wrote a few automated database-populating scripts. Specifically, I am running Microsoft SQL Server in a container in a Kubernetes cluster—okay, it&amp;#8217;s Red Hat OpenShift, but it&amp;#8217;s still Kubernetes. It was all fun and games until I started mixing Windows and Linux; I was developing on my Windows machine, but obviously the container is [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/06/why-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it/"&gt;Why Windows and Linux line endings don&amp;#8217;t line up (and how to fix it)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/05/06/why-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">894667</post-id><dc:creator>Don Schenck</dc:creator><dc:date>2021-05-06T07:00:54Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/05/06/why-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it/</feedburner:origLink></entry><entry><title>Automating the testing process for SystemTap, Part 1: Test automation with libvirt and Buildbot</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ikKoWxcNCcw/" /><category term="CI/CD" /><category term="Linux" /><category term="Open source" /><category term="Performance" /><category term="buildbot" /><category term="Linux kernel" /><category term="systemtap" /><category term="test automation" /><author><name>Serhei Makarov</name></author><id>https://developers.redhat.com/blog/?p=843537</id><updated>2021-05-06T07:00:12Z</updated><published>2021-05-06T07:00:12Z</published><content type="html">&lt;p&gt;Over the past year, I have been implementing an automated infrastructure to test the &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/systemtap/"&gt;SystemTap&lt;/a&gt; project and to collect and analyze the test results. SystemTap is a scripting language for creating instrumentation to observe a live running &lt;a target="_blank" rel="nofollow" href="/topics/linux"&gt;Linux&lt;/a&gt; kernel and user-space applications. The SystemTap language translator produces Linux kernel modules. These modules depend on internal details of the Linux kernel that vary significantly between different versions of Linux.&lt;/p&gt; &lt;p&gt;The process of developing the SystemTap project and maintaining it for a wide range of Linux kernel versions requires a strategy to detect and fix unexpected bugs. Bugs can arise not only from changes in the SystemTap project, but also from changes in newer versions of the Linux kernel.&lt;/p&gt; &lt;p&gt;In order to verify the safety and correct behavior of SystemTap, the SystemTap project includes a test suite based on the &lt;a target="_blank" rel="nofollow" href="https://www.gnu.org/software/dejagnu/"&gt;DejaGnu&lt;/a&gt; framework. However, up to now there was no system for running this test suite each time someone made a commit to the SystemTap Git repository. An infrastructure that automatically runs the test suite and reports new test failures would be very helpful for detecting and fixing bugs as early as possible during the SystemTap development process.&lt;/p&gt; &lt;p&gt;This article is the first of two articles summarizing the tools that I developed and used to automate the process of testing SystemTap and detecting test failures. For the purpose of these articles, I consider the testing process to consist of seven steps. I describe the implementation for each of these steps and finish by summarizing my key design ideas and outlining potential future improvements.&lt;/p&gt; &lt;p&gt;The ideas presented in these articles could be useful for other &lt;a target="_blank" rel="nofollow" href="/topics/open-source"&gt;open source&lt;/a&gt; projects with complex testing requirements.&lt;/p&gt; &lt;h2&gt;Seven steps for successful testing&lt;/h2&gt; &lt;p&gt;When developing an infrastructure for testing and test-result analysis, I found that commonly used &lt;a target="_blank" rel="nofollow" href="/topics/ci-cd"&gt;continuous integration&lt;/a&gt; (CI) systems are insufficient for testing SystemTap. Most CI systems assume a problem formulation in which a commit to a project should be accepted or rejected depending on whether testing the resulting version produces a &amp;#8220;pass&amp;#8221; or &amp;#8220;fail&amp;#8221; result on a specified set of test cases. This formulation is not sufficient for testing SystemTap.&lt;/p&gt; &lt;p&gt;An infrastructure for testing SystemTap must take several difficult concerns into account. The &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=systemtap.git;a=tree;f=testsuite"&gt;SystemTap test suite&lt;/a&gt; contains a large number of test cases that are nondeterministic or environment-sensitive. Some of these test cases are important, whereas others are included to monitor the availability of optional SystemTap functionality across different systems. It would be difficult to decide on a single &amp;#8220;pass&amp;#8221; or &amp;#8220;fail&amp;#8221; verdict for the entire set of test results.&lt;/p&gt; &lt;p&gt;A set of test results could contain a number of important test failures that indicate new bugs that should be fixed, intermixed with unimportant test failures that occur on a regular basis. Test failures could also arise because of changes in the test environment, particularly changes to kernel internals after a kernel update. Because these test failures are not caused by changes in SystemTap code, they cannot be prevented by rejecting or reverting a SystemTap commit. The only solution is to detect the test failure and to fix or extend SystemTap to support the changed environment.&lt;/p&gt; &lt;p&gt;To design an infrastructure for testing SystemTap, I analyzed the testing process from the top level and defined a testing scheme consisting of seven steps. Some of these steps could be automated with basic shell scripts and existing tools. Other steps required me to develop entirely new software for test result analysis.&lt;/p&gt; &lt;p&gt;The first three steps relate to testing the project and collecting test results. I determined that these steps could be handled with shell scripts and existing software—namely the &lt;a target="_blank" rel="nofollow" href="https://libvirt.org"&gt;libvirt&lt;/a&gt; virtual machine (VM) provisioning system and the &lt;a target="_blank" rel="nofollow" href="https://buildbot.net"&gt;Buildbot&lt;/a&gt; test-automation toolkit. These steps are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Step 1: Provisioning test machines and VMs.&lt;/li&gt; &lt;li&gt;Step 2: Installing the SystemTap project and running the test suite.&lt;/li&gt; &lt;li&gt;Step 3: Sending test results to a central location.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The remaining four steps pertain to storing the collected test results and to analyzing them to discover and report new test failures. To handle these steps, I developed a test result storage and analysis toolkit called &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=summary"&gt;Bunsen&lt;/a&gt;. These steps are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Step 4: Receiving and storing test results in a compact format.&lt;/li&gt; &lt;li&gt;Step 5: Querying the test results. When we obtain a new set of test results, we want to view those results and compare them with test results for earlier versions.&lt;/li&gt; &lt;li&gt;Step 6: Analyzing the test results. To filter out newly occurring test failures from previously occurring failures, we need to use information from the entire history of test results.&lt;/li&gt; &lt;li&gt;Step 7: Reporting the analysis in a readable format.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In terms of equipment, my testing infrastructure consists of a set of test machines and a server that acts as a &lt;em&gt;virtual machine host&lt;/em&gt; and &lt;em&gt;test result storage server&lt;/em&gt;. Currently, this infrastructure operates internally at Red Hat. Figure 1 summarizes the components of the testing infrastructure and how they interact.&lt;/p&gt; &lt;div id="attachment_843677" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/12/bunsen-2020-12-workflow.png"&gt;&lt;img aria-describedby="caption-attachment-843677" class="wp-image-843677" src="https://developers.redhat.com/blog/wp-content/uploads/2020/12/bunsen-2020-12-workflow.png" alt="The SystemTap testing infrastructure contains many components, whose interactions are shown in this figure." width="640" height="686" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-843677" class="wp-caption-text"&gt;Figure 1: Components of the SystemTap testing infrastructure and their interactions.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;This article explains in detail the first three steps of the testing process and how these steps are implemented by my testing infrastructure. I&amp;#8217;ll cover the remaining four steps in the next article.&lt;/p&gt; &lt;h2&gt;Step 1: Provisioning test machines and VMs&lt;/h2&gt; &lt;p&gt;The purpose of this step is to maintain a set of test machines with a range of hardware architectures and kernel versions. SystemTap must be tested on a wide variety of system configurations because of its complex dependencies on the Linux kernel’s internals and on the hardware architecture.&lt;/p&gt; &lt;p&gt;I found that maintaining the required set of test machines manually would entail a significant and recurring maintenance burden. My primary source of test machines was a virtual-machine server running the &lt;a target="_blank" rel="nofollow" href="https://www.linux-kvm.org/page/Main_Page"&gt;KVM&lt;/a&gt; hypervisor with the &lt;a target="_blank" rel="nofollow" href="https://libvirt.org"&gt;libvirt&lt;/a&gt; virtual-machine management tools. I was also able to provision test machines on a temporary basis from pools of hardware resources managed by systems such as &lt;a target="_blank" rel="nofollow" href="https://www.openstack.org"&gt;OpenStack&lt;/a&gt; or &lt;a target="_blank" rel="nofollow" href="https://beaker-project.org"&gt;Beaker&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;I needed to initialize each test machine with a Linux distribution and configure it to run the SystemTap test suite. Doing so manually would entail frequent repetitive work.&lt;/p&gt; &lt;p&gt;As I developed my testing infrastructure, it became clear that the best way to avoid repetitive manual maintenance would be to make it as simple as possible to provision new test machines.&lt;/p&gt; &lt;p&gt;Therefore, I developed &lt;code&gt;buildbot-create-vm.sh&lt;/code&gt;, a shell script that invokes the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/configuring_and_managing_virtualization/index#creating-virtual-machines-using-the-command-line-interface_assembly_creating-virtual-machines"&gt;virt-install&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://libguestfs.org/virt-customize.1.html"&gt;virt-customize&lt;/a&gt; commands to create and configure a virtual machine for testing SystemTap. &lt;code&gt;virt-install&lt;/code&gt; and &lt;code&gt;virt-customize&lt;/code&gt; are command-line tools, included in both the &lt;a target="_blank" rel="nofollow" href="https://libvirt.org"&gt;libvirt&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://libguestfs.org"&gt;libguestfs&lt;/a&gt; projects, that can automatically create a virtual machine and modify the contents of its filesystem. The example commands in this section are based on &lt;code&gt;buildbot-create-vm.sh&lt;/code&gt; and illustrate how the &lt;code&gt;virt-install&lt;/code&gt; and &lt;code&gt;virt-customize&lt;/code&gt; commands can be used.&lt;/p&gt; &lt;p&gt;The following command invokes &lt;code&gt;virt-install&lt;/code&gt; to create a new virtual machine:&lt;/p&gt; &lt;pre&gt;NAME=buildbot_example \ LOCATION=http://download.fedoraproject.org/pub/fedora/linux/development/33/Server/x86_64/os/ \ virt-install --name=$NAME --os-variant=fedora32 \ --vcpus 2 --memory 4096 \ --disk pool=default,size=25 \ --autostart --watchdog default \ --location=$LOCATION \ --network bridge=br0 \ --graphics=none --extra-args console=ttyS0 \ --unattended admin-password-file=$PASSWORD \ --noreboot &lt;/pre&gt; &lt;p&gt;This command assumes that a libvirt storage pool named &lt;code&gt;default&lt;/code&gt; is available for creating a new virtual disk. The &lt;code&gt;LOCATION&lt;/code&gt; variable specifies the URL of a mirror for network installation of Fedora Linux.&lt;/p&gt; &lt;p&gt;And the following command invokes &lt;code&gt;virt-customize&lt;/code&gt; to initialize the newly created VM with additional configuration:&lt;/p&gt; &lt;pre&gt;NAME=buildbot_example \ REPO_FILE=example_custom.repo \ BUILDBOT_INSTALL_SH=/path/to/buildbot-install.sh \ SSH_PUBLIC_KEY=$(cat id_rsa_casual.pub) \ virt-customize -d $NAME \ --hostname "$NAME.local" \ --copy-in $REPO_FILE:/etc/yum.repos.d \ --copy-in $BUILDBOT_INSTALL_SH:/root \ --append-line $'/etc/crontab:@reboot\troot\tbash -c "chmod +x /root/buildbot-install.sh; /root/buildbot-install.sh 2&amp;#62;&amp;#38;1 &amp;#62;/root/crontab-firstboot.log"' \ --edit $'/etc/ssh/sshd_config:s/^# ?PermitRootLogin .*/PermitRootLogin yes/' \ --mkdir /root/.ssh \ --append-line "/root/.ssh/authorized_keys:$SSH_PUBLIC_KEY" \ --chmod $'0600:/root/.ssh/authorized_keys' &lt;/pre&gt; &lt;p&gt;This command creates a crontab file that will run the script &lt;code&gt;buildbot-install-stap.sh&lt;/code&gt; when the VM starts running. As described in the next section, this script installs a SystemTap development environment and configures it for automated testing.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;REPO_FILE&lt;/code&gt; variable contains the name of a custom DNF package repository, while &lt;code&gt;BUILDBOT_INSTALL_SH&lt;/code&gt; specifies the location of the &lt;code&gt;buildbot-install-stap.sh&lt;/code&gt; script described in the next section. In addition, the &lt;code&gt;SSH_PUBLIC_KEY&lt;/code&gt; variable is initialized with an SSH public key that will be used for logging into the test machine remotely.&lt;/p&gt; &lt;h2&gt;Step 2: Installing the SystemTap project and running the test suite&lt;/h2&gt; &lt;p&gt;The purpose of this step is to set up the newly provisioned test machines with a SystemTap development environment and to configure the machines to launch the SystemTap test suite automatically whenever a commit is made to the main SystemTap Git repository on sourceware.org.&lt;/p&gt; &lt;p&gt;For setting up a SystemTap development environment, I developed several shell scripts: &lt;code&gt;buildbot-install-stap.sh&lt;/code&gt; and &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-guest/systemtap/stap-install.sh;hb=HEAD"&gt;stap-install.sh&lt;/a&gt; to install the developer tools required to build SystemTap, and &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-guest/systemtap/stap-test.sh;hb=HEAD"&gt;stap-test.sh&lt;/a&gt; to download, compile, and test the SystemTap project from source. These scripts assume that the test machine will be dedicated exclusively for testing SystemTap.&lt;/p&gt; &lt;p&gt;For long-term testing of SystemTap, it is safest to use a dedicated test machine, since the full SystemTap test suite includes a number of &amp;#8220;stress tests&amp;#8221; that deliberately weaken or disable some of SystemTap’s safety mechanisms. On rare occasions, a failure result for one of these test cases can produce a kernel panic or hard lockup.&lt;/p&gt; &lt;p&gt;Before launching the SystemTap test suite, &lt;code&gt;stap-test.sh&lt;/code&gt; performs a number of helpful configuration steps not handled by the SystemTap project’s &lt;code&gt;make installcheck&lt;/code&gt; test suite command, including the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;stap-test.sh&lt;/code&gt; ensures that a &lt;code&gt;kernel-devel&lt;/code&gt; package is installed with a version exactly matching the currently running kernel. A &lt;code&gt;kernel-devel&lt;/code&gt; package is required to allow SystemTap to compile kernel modules that can carry out system-wide observations. Because some distributions&amp;#8217; package repositories provide only the latest version of each package, the &lt;code&gt;kernel-devel&lt;/code&gt; package for the currently running kernel might no longer be available. In that case, &lt;code&gt;stap-test.sh&lt;/code&gt; updates the kernel to match the available version of the &lt;code&gt;kernel-devel&lt;/code&gt; package and reboots the test machine.&lt;/li&gt; &lt;li&gt;&lt;code&gt;stap-test.sh&lt;/code&gt; checks whether the &lt;a target="_blank" rel="nofollow" href="https://debuginfod.elfutils.org"&gt;debuginfod.elfutils.org&lt;/a&gt; server provides debuginfo for the Linux distribution and currently running kernel on the test machine, and accordingly enables or disables SystemTap&amp;#8217;s support for retrieving kernel debuginfo via &lt;code&gt;debuginfod&lt;/code&gt;. When &lt;code&gt;debuginfod&lt;/code&gt; support is disabled, &lt;code&gt;stap-test.sh&lt;/code&gt; runs the &lt;code&gt;stap-prep&lt;/code&gt; script provided by SystemTap to attempt to install a debuginfo package for the current kernel. More information about SystemTap&amp;#8217;s support for &lt;code&gt;debuginfod&lt;/code&gt; can be found in the article &lt;a target="_blank" rel="nofollow" href="/blog/2019/10/14/introducing-debuginfod-the-elfutils-debuginfo-server/"&gt;Introducing debuginfod, the elfutils debuginfo server&lt;/a&gt; by Aaron Merey.&lt;/li&gt; &lt;li&gt;&lt;code&gt;stap-test.sh&lt;/code&gt; runs the &lt;a target="_blank" rel="nofollow" href="https://man7.org/linux/man-pages/man1/dmesg.1.html"&gt;dmesg&lt;/a&gt; command to capture the Linux kernel ring buffer output into an additional file included with the final test results. In my experience, this output is important to capture because it may contain additional information about kernel warnings or crashes triggered by SystemTap test cases.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I’ve &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=tree;f=scripts-guest/systemtap;hb=HEAD"&gt;published&lt;/a&gt; the &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-guest/systemtap/stap-install.sh;hb=HEAD"&gt;stap-install.sh&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-guest/systemtap/stap-test.sh;hb=HEAD"&gt;stap-test.sh&lt;/a&gt; scripts for anyone who is interested in quickly setting up a SystemTap environment and running the test suite.&lt;/p&gt; &lt;p&gt;To launch the SystemTap test suite automatically across the full set of test machines, I use an instance of the &lt;a target="_blank" rel="nofollow" href="https://buildbot.net"&gt;Buildbot&lt;/a&gt; system. The Buildbot system runs on the test result server and accepts connections from Buildbot workers running on the test machines.&lt;/p&gt; &lt;p&gt;Whenever a new test machine is provisioned, a Buildbot worker is automatically installed and configured on the machine by &lt;code&gt;buildbot-install-stap.sh&lt;/code&gt;. After connecting to the Buildbot system, the Buildbot worker waits for testing requests.&lt;/p&gt; &lt;p&gt;The Buildbot service regularly checks the SystemTap Git repository on sourceware.org for new commits. When a commit is made to the SystemTap Git repository, the Buildbot service sends a request to the Buildbot worker on each of the test machines. The Buildbot workers then invoke the &lt;code&gt;stap-test.sh&lt;/code&gt; script.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;buildbot-install-stap.sh&lt;/code&gt; script can also be invoked manually on a test machine that was provisioned either by hand or from a pool of test machines managed by a system such as OpenStack or Beaker. This manual invocation option has proven useful for quickly setting up test machines on a variety of architectures besides x86.&lt;/p&gt; &lt;p&gt;The Buildbot system includes some functionality for collecting and displaying test results, but I decided not to rely on it. Buildbot assumes a testing process that is modeled as a series of stages, and each of these stages is expected to have a simple &amp;#8220;pass&amp;#8221; or &amp;#8220;fail&amp;#8221; outcome. As mentioned earlier, this model is appropriate for a continuous integration system, but is too simple for a project such as SystemTap whose test suite includes many nondeterministic or environment-dependent test cases.&lt;/p&gt; &lt;h2&gt;Step 3: Sending test results to a central location&lt;/h2&gt; &lt;p&gt;The purpose of this step is to collect in one location the SystemTap test results produced by the various test machines.&lt;/p&gt; &lt;p&gt;After running the SystemTap test suite, the &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-guest/systemtap/stap-test.sh;hb=HEAD"&gt;stap-test.sh&lt;/a&gt; script packages the test results in a tar archive and sends them to the test result server. The test results produced by SystemTap’s &lt;a target="_blank" rel="nofollow" href="https://www.gnu.org/software/dejagnu/"&gt;DejaGnu&lt;/a&gt; test suite consist of a &lt;code&gt;systemtap.log&lt;/code&gt; and a &lt;code&gt;systemtap.sum&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;systemtap.log&lt;/code&gt; file contains the detailed output of every test case in the test suite, while the &lt;code&gt;systemtap.sum&lt;/code&gt; file contains a condensed summary of the results for each test case.&lt;/p&gt; &lt;p&gt;In addition to the DejaGnu output, the &lt;code&gt;stap-test.sh&lt;/code&gt; script also sends a file of system diagnostics collected by the &lt;a target="_blank" rel="nofollow" href="https://man7.org/linux/man-pages/man1/stap-report.1.html"&gt;stap-report&lt;/a&gt; command, as well as a file named &lt;code&gt;systemtap.dmesg&lt;/code&gt; containing kernel ring buffer data captured during the test suite execution.&lt;/p&gt; &lt;p&gt;The following command from &lt;code&gt;stap-test.sh&lt;/code&gt; packages and sends the test result log files to the test result server:&lt;/p&gt; &lt;pre&gt;tar cvzf - $LOGPATH/systemtap.log* $LOGPATH/systemtap.sum* $LOGPATH/systemtap.dmesg* $LOGPATH/stap-report.* | curl -X POST -F 'project=systemtap' -F 'tar=@-' $BUNSEN_URL/bunsen-upload.py &lt;/pre&gt; &lt;p&gt;Here, the variable &lt;code&gt;LOGPATH&lt;/code&gt; specifies the location of the test result log files and the variable &lt;code&gt;BUNSEN_URL&lt;/code&gt; specifies the location of the test result server.&lt;/p&gt; &lt;p&gt;On the test result server, test results are accepted by a CGI script that adds the log files to a test-result repository managed by the Bunsen toolkit, as described in the next article in the series.&lt;/p&gt; &lt;h2&gt;To be continued &amp;#8230;&lt;/h2&gt; &lt;p&gt;This article described the automated testing infrastructure I developed for the SystemTap project. The next article will describe Bunsen, the toolkit I developed for test result storage and analysis.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#038;title=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" data-a2a-url="https://developers.redhat.com/blog/2021/05/06/automating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot/" data-a2a-title="Automating the testing process for SystemTap, Part 1: Test automation with libvirt and Buildbot"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/06/automating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot/"&gt;Automating the testing process for SystemTap, Part 1: Test automation with libvirt and Buildbot&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ikKoWxcNCcw" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Over the past year, I have been implementing an automated infrastructure to test the SystemTap project and to collect and analyze the test results. SystemTap is a scripting language for creating instrumentation to observe a live running Linux kernel and user-space applications. The SystemTap language translator produces Linux kernel modules. These modules depend on internal [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/06/automating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot/"&gt;Automating the testing process for SystemTap, Part 1: Test automation with libvirt and Buildbot&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/05/06/automating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">843537</post-id><dc:creator>Serhei Makarov</dc:creator><dc:date>2021-05-06T07:00:12Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/05/06/automating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot/</feedburner:origLink></entry><entry><title type="html">The path to OptaPlanner enlightenment starts in the logs</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/qylisYXmQxA/the-path-to-optaplanner-enlightenment-starts-in-the-logs.html" /><author><name>Geoffrey De Smet</name></author><id>https://blog.kie.org/2021/05/the-path-to-optaplanner-enlightenment-starts-in-the-logs.html</id><updated>2021-05-06T00:00:17Z</updated><content type="html">Do you want to understand what OptaPlanner is doing while it is solving? Which decisions it makes? When? And why? Do you want to open the box and take a look inside? If so, keep reading. The Age of Enlightenment centered on the use of reason and the evidence of the senses. Similarly, OptaPlanner enlightenment starts with the use of reason and the evidence in the logs. OK. That’s enough philosophy for this article… It’s time to open the box. Take a look at the log for : 12:18:04 INFO Solving started: time spent (196), best score (-38init/0hard/0soft), environment mode (REPRODUCIBLE), move thread count (NONE), random (JDK with seed 0). 12:18:04 INFO Construction Heuristic phase (0) ended: time spent (330), best score (0hard/-11soft), score calculation speed (4358/sec), step total (19). 12:18:34 INFO Local Search phase (1) ended: time spent (30000), best score (0hard/10soft), score calculation speed (12786/sec), step total (26654). 12:18:34 INFO Solving ended: time spent (30000), best score (0hard/10soft), score calculation speed (12663/sec), phase total (2), environment mode (REPRODUCIBLE), move thread count (NONE). This is a lot of information, even on the INFO level. Let’s investigate each nugget of information in there, one by one: WHEN DID THE SOLVER RUN? The log shows when the solver started and when it ended: 12:18:04 INFO Solving started ... ... 12:18:34 INFO Solving ended ... That’s useful in complex applications with other log lines intertwined. WHAT IS THE SOLVER DOING? It also displays what the solver did while solving: 12:18:04 INFO Solving started ... 12:18:04 INFO Construction Heuristic phase (0) ended ... 12:18:34 INFO Local Search phase (1) ended ... 12:18:34 INFO Solving ended ... It ran two algorithm phases sequentially: * Phase 0: a Construction Heuristic to provide an initial solution for the problem * Phase 1: a Local Search to improve the solution further Here’s an illustration of those phases on the N-Queens and the Cloud Balancing examples: If the Local Search log line is missing (after the solver ends), the Construction Heuristic did not have enough time to initialize the entire solution, leaving no time for the Local Search algorithm. That returns an incomplete or infeasible solution. TIME SPENT The log also exhibits how long each of those phases took, in milliseconds, relevant to the start of the solver: 12:18:04 INFO Solving started time spent (196) ... 12:18:04 INFO Construction Heuristic ended ... time spent (330) ... 12:18:34 INFO Local Search ended ... time spent (30000) ... 12:18:34 INFO Solving ended time spent (30000), ... * The Solver initialization took 196 milliseconds. * The Construction Heuristic took 330 - 196 = 134 milliseconds. * For big datasets, if the CH takes more than one minute, it’s worth investigating why, even if the solver runs for hours. * The Local Search took 30000 - 330 = 29670 milliseconds. * LS gets the lion’s share of the time, as it should be. SCORE QUALITY The log also reveals the solution quality after each algorithm: INFO Solving started ... best score (-38init/0hard/0soft) ... INFO Construction Heuristic ended ... best score (0hard/-11soft) ... INFO Local Search ended ... best score (0hard/10soft) ... INFO Solving ended ... best score (0hard/10soft) ... * The starting score -38init/0hard/0soft indicates there are 38 unassigned planning variables. That’s because there are 19 lessons, each with 2 planning variables to initialize. * The Construction Heuristic ends with a solution of score 0hard/-11soft, which is already feasible (no hard constraints broken). That’s not always the case. * The Local Search improves the score further to score 0hard/10soft. That’s an difference of +21soft in 29 seconds. PERFORMANCE There’s also performance information to discover in the log. First ensure it’s an apples-to-apples comparison: 12:18:04 INFO Solving started ... environment mode (REPRODUCIBLE), move thread count (NONE) ... ... 12:18:34 INFO Solving ended ... environment mode (REPRODUCIBLE), move thread count (NONE). * If the environment mode is any ASSERT mode, performance is irrelevant, because the extra assertions are very expensive performance wise. * The move thread count indicates how many extra CPU cores it can consume. * NONE means all move calculations happen inside the solver’s thread, so only 1 CPU is exploited. Both of these affect the score calculation speed, which shows how many moves were evaluated, normalized per second, for the solver entirely, but also each phase separately: 12:18:04 INFO Solving started ... 12:18:04 INFO Construction Heuristic ended ... score calculation speed (4358/sec) ... 12:18:34 INFO Local Search ... score calculation speed (12786/sec) ... 12:18:34 INFO Solving ended ... score calculation speed (12663/sec) ... * The Construction Heuristic evaluated over 4000 moves per second. * That’s actually pretty low, but it only ran for 134 milliseconds, so the overhead weighs in too much, lowering the number significantly. It should be run with a bigger dataset instead. * Normally, the score calculation speed of the Construction Heuristic is higher than that of the Local Search, because it’s faster to calculate the score when half of the entities aren’t initialized yet. * The Local Search evaluated over 12000 moves per second. * That’s good. The LS score calculation speed should always be above 10 000 per second, even for big datasets. * Do note that it ran for 29 seconds and a JVM can take a minute to warm up. Keep an eye on the score calculation when adding/editing constraints, running the solver for same amount of time (typically 1 minute), to discover performance bottlenecks early. For more accurate performance investigations, use optaplanner-benchmark which supports warming up. STEPS In essence, both the Construction Heuristic phase and Local Search phase run a double loop: for (Step step : steps) { // Outer loop for (Move move : moves) { // Inner loop // Evaluate move } // Take step } The outer, step loop executes the best move found by the inner, move loop. Of course, this is a gross simplification: there are dozens of orthogonal AI subsystems on top of it. It’s only the tip of the iceberg. But it’s an honest simplification. The INFO log shows how many of these outer loop iterations both phases did: ... 12:18:04 INFO Construction Heuristic ended ... step total (19). 12:18:34 INFO Local Search ended ... step total (26654). ... * The Construction Heuristic did 19 steps. That’s because there are 19 lessons in the dataset. Each step assigns one lesson. * The Local Search did over 26 000 steps. It continues iterating until the termination condition is hit. Each step modifies (often improves) the current solution. Turn on DEBUG logging to get a log line per step too: INFO Solving started: time spent (619), best score (-38init/0hard/0soft), environment mode (REPRODUCIBLE), move thread count (NONE), random (JDK with seed 0). DEBUG CH step (0), time spent (650), score (-36init/0hard/0soft), selected move count (30), picked move ([Biology(18) {null -&gt; Room A}, Biology(18) {null -&gt; MONDAY 09:30}]). DEBUG CH step (1), time spent (661), score (-34init/0hard/0soft), selected move count (30), picked move ([Chemistry(28) {null -&gt; Room A}, Chemistry(28) {null -&gt; MONDAY 10:30}]). DEBUG CH step (2), time spent (672), score (-32init/0hard/0soft), selected move count (30), picked move ([Chemistry(17) {null -&gt; Room A}, Chemistry(17) {null -&gt; MONDAY 13:30}]). ... DEBUG CH step (17), time spent (741), score (-2init/0hard/-10soft), selected move count (30), picked move ([Spanish(22) {null -&gt; Room B}, Spanish(22) {null -&gt; TUESDAY 10:30}]). DEBUG CH step (18), time spent (744), score (0hard/-11soft), selected move count (30), picked move ([Spanish(23) {null -&gt; Room B}, Spanish(23) {null -&gt; TUESDAY 14:30}]). INFO Construction Heuristic phase (0) ended: time spent (768), best score (0hard/-11soft), score calculation speed (3910/sec), step total (19). DEBUG LS step (0), time spent (790), score (0hard/-5soft), new best score (0hard/-5soft), accepted/selected move count (1/1), picked move (Physics(27) {Room B, MONDAY 08:30} &lt;-&gt; Math(14) {Room A, MONDAY 08:30}). DEBUG LS step (1), time spent (791), score (0hard/-7soft), best score (0hard/-5soft), accepted/selected move count (1/2), picked move (Spanish(33) {Room B -&gt; Room C}). ... DEBUG LS step (19071), time spent (29996), score (0hard/7soft), best score (0hard/10soft), accepted/selected move count (1/25), picked move (Geography(30) {Room C -&gt; Room B}). DEBUG LS step (19072), time spent (30000), score (0hard/5soft), best score (0hard/10soft), accepted/selected move count (0/25), picked move (English(20) {Room A, MONDAY 10:30} &lt;-&gt; Math(14) {Room A, MONDAY 14:30}). INFO Local Search phase (1) ended: time spent (30000), best score (0hard/10soft), score calculation speed (7927/sec), step total (19073). INFO Solving ended: time spent (30000), best score (0hard/10soft), score calculation speed (7858/sec), phase total (2), environment mode (REPRODUCIBLE), move thread count (NONE). Again, this is a lot of information to digest. The DEBUG lines display when a Local Search step improves the best solution: INFO Construction Heuristic ... best score (0hard/-11soft) ... DEBUG LS step (0) ... score (0hard/-5soft), new best score (0hard/-5soft) ... DEBUG LS step (1) ... score (0hard/-7soft), best score (0hard/-5soft) ... ... * LS step 0 improved the best solution from -11soft to -5soft. * LS step 1 didn’t improve the best solution of -5soft. * It actually accepted a worse solution of -7soft, which is mechanism to escape local optima, to improve the best solutions in later steps. The DEBUG log even shows the winning move: DEBUG LS step (0) ... picked move (Physics(27) {Room B, MONDAY 08:30} &lt;-&gt; Math(14) {Room A, MONDAY 08:30}). This move swapped the Physics lesson with the Math lesson. The toString() method of your domain classes should return a short string (typically a name and/or ID) to keep the logs readable. MOVES The DEBUG log reveals the number of moves selected per step, which is the number of inner loop iterations: ... DEBUG CH step (17) ... selected move count (30) ... DEBUG CH step (18) ... selected move count (30) ... INFO Construction Heuristic ended ... DEBUG LS step (0) ... accepted/selected move count (1/1) ... DEBUG LS step (1) ... accepted/selected move count (1/2) ... ... INFO Local Search phase (1) ended ... Turn on TRACE logging to get a log line per move too, which exposes the score of each move evaluation: INFO Construction Heuristic ... time spent (395), best score (0hard/-11soft) ... TRACE Move index (0), score (0hard/-5soft) ... DEBUG LS step (0) ... score (0hard/-5soft), new best score (0hard/-5soft) ... TRACE Move index (0), score (-2hard/-6soft) ... TRACE Move index (1), score (0hard/-7soft) ... DEBUG LS step (1) ... score (0hard/-7soft), best score (0hard/-5soft) ... TRACE Move index (0), score (-3hard/-7soft) ... TRACE Move index (1) not doable, ignoring move ... TRACE Move index (2), score (-2hard/-9soft) ... TRACE Move index (3), score (-2hard/-6soft) ... TRACE Move index (4), score (-2hard/-7soft) ... TRACE Move index (5), score (-1hard/-8soft) ... TRACE Move index (6), score (0hard/-4soft) ... DEBUG LS step (2) ... score (0hard/-4soft), new best score (0hard/-4soft) ... Again, each TRACE line also shows the selected move: TRACE Move index (0) ... move (Chemistry(28) {Room C -&gt; Room A}). This move changed the room of the Chemistry lesson. GET STARTED Get started on your OptaPlanner enlightenment path today! Turn on logging in: * Plain Java: Add a dependency on logback-classic and the logback.xml file: &lt;configuration&gt; &lt;logger name="org.optaplanner" level="debug"/&gt; &lt;/configuration&gt; Or instead, add a dependency on an slf4j bridge to your favorite logging system. * : Add this line in application.properties: quarkus.log.category."org.optaplanner".level=DEBUG * Spring Boot: Add this line in application.properties: logging.level.org.optaplanner=DEBUG The log is your friend! It tells you what is doing. Keep an eye on it. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/qylisYXmQxA" height="1" width="1" alt=""/&gt;</content><dc:creator>Geoffrey De Smet</dc:creator><feedburner:origLink>https://blog.kie.org/2021/05/the-path-to-optaplanner-enlightenment-starts-in-the-logs.html</feedburner:origLink></entry><entry><title type="html">Quarkus 2.0.0.Alpha2 released - Continuous Testing improvements</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/V1xaEpyvv5c/" /><author><name /></author><id>https://quarkus.io/blog/quarkus-2-0-0-alpha2-released/</id><updated>2021-05-06T00:00:00Z</updated><content type="html">We just released our second Alpha for Quarkus 2.0. We had a lot of feedback and Continuous Testing got a lot of fixes and improvements. Please keep the feedback coming! If you have missed our Alpha1 announcement: here are the main new features of Quarkus 2.0. Migration Guide We will...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/V1xaEpyvv5c" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/quarkus-2-0-0-alpha2-released/</feedburner:origLink></entry><entry><title>Kubernetes configuration patterns, Part 2: Patterns for Kubernetes controllers</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/BdmUqPDxuj4/" /><category term="Containers" /><category term="DevOps" /><category term="Kubernetes" /><category term="Configuring Kubernetes" /><category term="kubernetes api" /><category term="Kubernetes controller patterns" /><author><name>Ali Ok</name></author><id>https://developers.redhat.com/blog/?p=825297</id><updated>2021-05-05T07:00:59Z</updated><published>2021-05-05T07:00:59Z</published><content type="html">&lt;p&gt;This article is the second in a two-part article series on &lt;a target="_blank" rel="nofollow" href="/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; configuration patterns, which you can use to configure your Kubernetes applications and controllers. The first article &lt;a target="_blank" rel="nofollow" href="/blog/2021/04/28/kubernetes-configuration-patterns-part-1-patterns-for-kubernetes-primitives/"&gt;introduced patterns and antipatterns that use only Kubernetes primitives&lt;/a&gt;. Those simple patterns are applicable to any application. This second article describes more advanced patterns that require coding against the Kubernetes API, which is what a Kubernetes controller should use.&lt;/p&gt; &lt;p&gt;The patterns you will learn in this article are suitable for scenarios where the basic Kubernetes features are not enough. These patterns will help you when you can&amp;#8217;t mount a &lt;code&gt;ConfigMap&lt;/code&gt; from another namespace into a &lt;code&gt;Pod&lt;/code&gt;, can&amp;#8217;t reload the configuration without killing the &lt;code&gt;Pod&lt;/code&gt;, and so on.&lt;/p&gt; &lt;p&gt;As in the first article, for simplicity, I&amp;#8217;ve used only &lt;code&gt;Deployment&lt;/code&gt;s in the example YAML files. However, the examples should work with other &lt;em&gt;PodSpecables&lt;/em&gt; (anything that describes a &lt;code&gt;PodSpec&lt;/code&gt;) such as &lt;code&gt;DaemonSet&lt;/code&gt;s and &lt;code&gt;ReplicaSet&lt;/code&gt;s. I have also omitted fields like &lt;code&gt;image&lt;/code&gt;, &lt;code&gt;imagePullPolicy&lt;/code&gt;, and others in the example &lt;code&gt;Deployment&lt;/code&gt; YAML.&lt;/p&gt; &lt;h2&gt;&lt;a name="advanced_1"&gt;&lt;/a&gt;Configuration with central ConfigMaps&lt;/h2&gt; &lt;p&gt;It isn&amp;#8217;t possible to mount a &lt;code&gt;ConfigMap&lt;/code&gt; to a &lt;code&gt;Deployment&lt;/code&gt;, &lt;code&gt;Pod&lt;/code&gt;, &lt;code&gt;ReplicaSet&lt;/code&gt;, or other components, when they are in separate namespaces. In some cases though, you need a single central configuration store for components that run in different namespaces. The following &lt;code&gt;Deployment&lt;/code&gt; illustrates the situation:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: ConfigMap metadata: name: logcollector-config namespace: logcollector data: buffer: "2048" target: "file" --- apiVersion: apps/v1 kind: Deployment metadata: name: logcollector-agent namespace: user-ns-1 spec: ... template: spec: containers: - name: server --- apiVersion: apps/v1 kind: Deployment metadata: name: logcollector-agent namespace: user-ns-2 spec: ... template: spec: containers: - name: server &lt;/pre&gt; &lt;p&gt;In this example, imagine there is a central log collector system, as shown in Figure 1. A Kubernetes controller (not shown in the example) creates a separate log collector agent &lt;code&gt;Deployment&lt;/code&gt; for each namespace. That is why the &lt;code&gt;ConfigMap&lt;/code&gt; and &lt;code&gt;Deployment&lt;/code&gt; namespaces are different.&lt;/p&gt; &lt;div id="attachment_825127" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_1.png"&gt;&lt;img aria-describedby="caption-attachment-825127" class="wp-image-825127" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_1.png" alt="In this Kubernetes controller pattern, different containers in different namespaces retrieve their configuration by reading from a centralized ConfigMap." width="640" height="368" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_1.png 916w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_1-300x172.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_1-768x441.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-825127" class="wp-caption-text"&gt;Figure 1: Different containers read from a centralized ConfigMap.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In the log collector agents within each namespace, the agent application reads the central &lt;code&gt;ConfigMap&lt;/code&gt; for configuration. Please note that the &lt;code&gt;ConfigMap&lt;/code&gt; is not mounted to the container. The application needs to use the Kubernetes API to read the &lt;code&gt;ConfigMap&lt;/code&gt;, as the following pseudocode shows:&lt;/p&gt; &lt;pre&gt;package main import ... func main(){ if _, err := kubeclient.Get(ctx).CoreV1().ConfigMaps("logcollector").Get("logcollector-config", metav1.GetOptions{}); err == nil { watchConfigmap("logcollector" ,"logcollector-config", func(configMap *v1.ConfigMap) { updateConfig(configMap) }) } else if apierrors.IsNotFound(err) { log.Fatal("Central ConfigMap 'logcollector-config' in namespace 'logcollector' does not exist") } else { log.Fatal("Error reading central ConfigMap 'logcollector-config' in namespace 'logcollector'") } } &lt;/pre&gt; &lt;p&gt;This pseudocode gets the &lt;code&gt;ConfigMap&lt;/code&gt; and starts watching it. If there is any change to the &lt;a href="#advanced_1"&gt;ConfigMap&lt;/a&gt;, the function updates the configuration. It is not necessary to roll out a new &lt;code&gt;Deployment&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;As the &lt;code&gt;ConfigMap&lt;/code&gt; is in another namespace, containers need additional permissions for getting, reading and watching it. System administrators should handle the role-based access control (RBAC) settings for the containers. These settings are not shown here for brevity.&lt;/p&gt; &lt;h2&gt;&lt;a name="advanced_2"&gt;&lt;/a&gt;Configuration with central and namespaced ConfigMaps&lt;/h2&gt; &lt;p&gt;The &lt;a href="#advanced_1"&gt;Configuration with central ConfigMaps&lt;/a&gt; pattern lets you use a central configuration. In many cases, you also need to override some part of the configuration for each namespace.&lt;/p&gt; &lt;p&gt;This pattern uses a &lt;em&gt;namespaced configuration&lt;/em&gt; in addition to the central configuration. A separate watch is needed for the namespaced &lt;code&gt;ConfigMap&lt;/code&gt; in the code, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_825147" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_2.png"&gt;&lt;img aria-describedby="caption-attachment-825147" class="wp-image-825147" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_2.png" alt="In this Kubernetes controller pattern, each container takes its configuration from a centralized and a local ConfigMap." width="640" height="328" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_2.png 930w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_2-300x154.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_2-768x394.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-825147" class="wp-caption-text"&gt;Figure 2: Each container takes its config from a centralized configuration and a local ConfigMap.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Here is the &lt;code&gt;Deployment&lt;/code&gt; that sets up the namespaces and configurations:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: ConfigMap metadata: name: logcollector-config namespace: logcollector data: buffer: "2048" --- apiVersion: v1 kind: ConfigMap metadata: name: logcollector-config namespace: user-ns-1 data: buffer: "1024" target: "file" --- apiVersion: apps/v1 kind: Deployment metadata: labels: app: logcollector name: logcollector-deployment namespace: user-ns-1 spec: ... template: spec: containers: - name: server env: - name: NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace &lt;/pre&gt; &lt;p&gt;For brevity, the &lt;code&gt;Deployment&lt;/code&gt; in namespace &lt;code&gt;user-ns-2&lt;/code&gt; is not shown in the preceding YAML. It is exactly the same as the &lt;code&gt;Deployment&lt;/code&gt; in namespace &lt;code&gt;user-ns-1&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;There are two &lt;code&gt;ConfigMap&lt;/code&gt;s now. One is in the &lt;code&gt;logcollector&lt;/code&gt; namespace that is considered the central configuration. The other is in the same namespace as the log collector instance in the &lt;code&gt;user-ns-1&lt;/code&gt; namespace. The code for retrieving the configurations is:&lt;/p&gt; &lt;pre&gt;package main import ... func main(){ if namespace := os.Getenv("NAMESPACE"); ns == "" { panic("Unable to determine application namespace") } var central *v1.ConfigMap var local *v1.ConfigMap if _, err := kubeclient.Get(ctx).CoreV1().ConfigMaps("logcollector").Get("logcollector-config", metav1.GetOptions{}); err == nil { watchConfigmap("logcollector" ,"logcollector-config", func(configMap *v1.ConfigMap) { central = configMap config := mergeConfig(central, local) updateConfig(config) }) } else if apierrors.IsNotFound(err) { log.Fatal("Central ConfigMap 'logcollector-config' in namespace 'logcollector' does not exist") } else { log.Fatal("Error reading central ConfigMap 'logcollector-config' in namespace 'logcollector'") } if _, err := kubeclient.Get(ctx).CoreV1().ConfigMaps(namespace).Get("logcollector-config", metav1.GetOptions{}); err == nil { watchConfigmap(namespace ,"logcollector-config", func(configMap *v1.ConfigMap) { central = configMap config := mergeConfig(central, local) updateConfig(config) }) } else if apierrors.IsNotFound(err) { log.Infof("Local ConfigMap 'logcollector-config' in namespace '%s' does not exist", namespace) } else { log.Fatalf("Error reading local ConfigMap 'logcollector-config' in namespace '%s'", namespace) } } func mergeConfig(central, local *v1.ConfigMap) (...){ // merge 2 configmaps here and return the result } &lt;/pre&gt; &lt;p&gt;The Kubernetes controller application will check the central config first, then the namespaced config. The configuration in the namespaced &lt;code&gt;ConfigMap&lt;/code&gt; will have precedence.&lt;/p&gt; &lt;h2&gt;Notes about the pattern&lt;/h2&gt; &lt;p&gt;It is okay to not have any local &lt;code&gt;ConfigMap&lt;/code&gt;s. Unlike when the central &lt;code&gt;ConfigMap&lt;/code&gt; is missing, the program will not stop execution if the local &lt;code&gt;ConfigMap&lt;/code&gt; does not exist.&lt;/p&gt; &lt;p&gt;The application needs to know the container namespace in which it is running, because the local &lt;code&gt;ConfigMap&lt;/code&gt; is not mounted using the &lt;code&gt;ConfigMap&lt;/code&gt; mounting and the application needs to issue a GET for the local &lt;code&gt;ConfigMap&lt;/code&gt;. Therefore, the application needs to tell the Kubernetes API the namespace it is looking in for the &lt;code&gt;ConfigMap&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;It would also be possible to simply mount the namespaced &lt;code&gt;ConfigMap&lt;/code&gt; into the log collector container. But in that case, you would lose the ability to reload the config without any restarts.&lt;/p&gt; &lt;h2&gt;&lt;a name="advanced_3"&gt;&lt;/a&gt;Configuration with custom resources&lt;/h2&gt; &lt;p&gt;You can use custom resources to extend the Kubernetes API. A custom resource is a very powerful concept, but too complicated to explain in depth here. A sample custom resource follows:&lt;/p&gt; &lt;pre&gt;apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: name: eventconsumers.example.com spec: group: example.com versions: - name: v1 ... scope: Namespaced names: plural: eventconsumers singular: eventconsumer kind: EventConsumer ... &lt;/pre&gt; &lt;p&gt;After applying this custom resource definition, you can create an &lt;code&gt;EventConsumer&lt;/code&gt; resource on Kubernetes:&lt;/p&gt; &lt;pre&gt;apiVersion: example.com/v1 kind: EventConsumer metadata: name: consumer-1 namespace: user-ns-1 spec: source: source1.foobar.com:443 --- apiVersion: example.com/v1 kind: EventConsumer metadata: name: consumer-2 namespace: user-ns-2 spec: source: source2.foobar.com:443 &lt;/pre&gt; &lt;p&gt;Custom resources can be used as configurations to be read by the Kubernetes controller, as shown in Figures 3 and 4. Figure 3 shows that the controller reads the custom resources.&lt;/p&gt; &lt;div id="attachment_825157" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_3_a.png"&gt;&lt;img aria-describedby="caption-attachment-825157" class="wp-image-825157" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_3_a.png" alt="In this Kubernetes controller pattern, custom resources are used to configure applications." width="640" height="369" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_3_a.png 929w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_3_a-300x173.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_3_a-768x443.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-825157" class="wp-caption-text"&gt;Figure 3: The controller reads each custom resource.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 4 shows that after the controller reads and processes the custom resources, it creates an event consumer application instance per custom resource.&lt;/p&gt; &lt;div id="attachment_825167" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_3_b.png"&gt;&lt;img aria-describedby="caption-attachment-825167" class="wp-image-825167" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_3_b.png" alt="In this Kubernetes controller pattern, the configuration adds custom resources." width="640" height="390" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_3_b.png 930w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_3_b-300x183.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_3_b-768x468.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-825167" class="wp-caption-text"&gt;Figure 4: The controller creates event consumer application instances for each custom resource.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In this case, the &lt;code&gt;EventConsumer&lt;/code&gt; custom resource provides a configuration for the event consumption applications that are created by the event consumer Kubernetes controller.&lt;/p&gt; &lt;p&gt;Note the &lt;code&gt;scope: Namespaced&lt;/code&gt; key and value in the custom resource definition. This tells Kubernetes that the custom resources created for this definition will live in a namespace.&lt;/p&gt; &lt;p&gt;A strong API for fields in the config is a nice feature. With rules defined in the custom resource definition, you can use a Kubernetes validation without any hassle.&lt;/p&gt; &lt;h2&gt;Drawbacks to configuration with custom resources&lt;/h2&gt; &lt;p&gt;A custom resource is less flexible than a &lt;code&gt;ConfigMap&lt;/code&gt;. It is possible to add data in any shape in a &lt;code&gt;ConfigMap&lt;/code&gt;. Also, it is not necessary to register a &lt;code&gt;ConfigMap&lt;/code&gt; in Kubernetes; you just create it. You must register custom resources by creating a &lt;code&gt;CustomResourceDefinition&lt;/code&gt;. The information you add in a custom resource should match the shape defined in the &lt;code&gt;CustomResourceDefinition&lt;/code&gt;. As stated earlier, a strong API is often considered a best practice. Even though &lt;code&gt;ConfigMap&lt;/code&gt;s are more flexible, using well-defined shapes for configuration is a good idea whenever possible.&lt;/p&gt; &lt;p&gt;Additionally, not everything can be specified strongly in advance. Imagine a program that can connect to multiple databases. The database clients will have different configurations and their shapes will be different. It will not be possible to simply define fields in the custom resource to pass them as a whole to the database client. It is not a good idea to create a custom resource that has a super large shape definition, because it can be in multiple shapes.&lt;/p&gt; &lt;p&gt;Additionally, the custom resource definition must be maintained carefully, and you cannot simply delete fields or update fields in an incompatible way without releasing a new version of the custom resource. There is no problem with adding new fields.&lt;/p&gt; &lt;h2&gt;&lt;a name="advanced_4"&gt;&lt;/a&gt;Configuration with custom resources, falling back to ConfigMaps&lt;/h2&gt; &lt;p&gt;This pattern is a mix of the &lt;a href="#advanced_3"&gt;Configuration with custom resources&lt;/a&gt; pattern and &lt;a href="#advanced_2"&gt;Configuration with central and namespaced ConfigMaps&lt;/a&gt; patterns.&lt;/p&gt; &lt;p&gt;In this pattern, configuration options that cannot be used in every scenario are placed in custom resources. Options that could be held in common by different custom resources are placed in &lt;code&gt;ConfigMap&lt;/code&gt;s so that they can be shared. This pattern is shown in Figures 5 and 6. Figure 5 shows that the controller is watching and reading the user-namespaced &lt;code&gt;ConfigMap&lt;/code&gt; and the custom resources. However, it relies first on the custom resources, falling back to &lt;code&gt;ConfigMap&lt;/code&gt; for values missing in the custom resources.&lt;/p&gt; &lt;div id="attachment_825177" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_4_a.png"&gt;&lt;img aria-describedby="caption-attachment-825177" class="wp-image-825177" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_4_a.png" alt="In this Kubernetes controller pattern, the controller creates the application landscape based on the custom resources and ConfigMaps." width="640" height="475" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_4_a.png 929w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_4_a-300x223.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_4_a-768x570.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-825177" class="wp-caption-text"&gt;Figure 5: The controller creates the application landscape based on custom resources and ConfigMaps.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 6 shows the application landscape created by the controller for the configuration given in Figure 5.&lt;/p&gt; &lt;div id="attachment_825187" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_4_b.png"&gt;&lt;img aria-describedby="caption-attachment-825187" class="wp-image-825187" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_4_b.png" alt="In this Kubernetes controller pattern, the configuration relies first on custom resources, falling back to ConfigMaps." width="640" height="420" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_4_b.png 930w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_4_b-300x197.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_4_b-768x504.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-825187" class="wp-caption-text"&gt;Figure 6: The configuration relies first on custom resources, falling back to ConfigMaps.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Here is the &lt;code&gt;Deployment&lt;/code&gt; that sets up the configurations, starting with the custom resource definition:&lt;/p&gt; &lt;pre&gt;apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: name: eventconsumers.example.com spec: group: example.com versions: - name: v1 ... scope: Namespaced names: plural: eventconsumers singular: eventconsumer kind: EventConsumer ... --- apiVersion: example.com/v1 kind: EventConsumer metadata: name: consumer-1 namespace: user-ns-1 spec: source: source1.foobar.com:443 --- apiVersion: example.com/v1 kind: EventConsumer metadata: name: consumer-2 namespace: user-ns-2 spec: source: source2.foobar.com:443 privateKey: | -----BEGIN PRIVATE KEY----- foobarbazfoobar barfoobarbazfoo bazfoobarfoobar -----END PRIVATE KEY----- &lt;/pre&gt; &lt;p&gt;And here is the &lt;code&gt;ConfigMap&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: ConfigMap metadata: name: eventconsumer-config namespace: eventconsumer data: buffer: "2048" privateKey: | -----BEGIN PRIVATE KEY----- MIICdQIBADANBgk nC45zqIvd1QXloq bokumO0HhjqI12a -----END PRIVATE KEY----- --- apiVersion: v1 kind: ConfigMap metadata: name: eventconsumer-config namespace: user-ns-1 data: buffer: "4096" &lt;/pre&gt; &lt;p&gt;In the example, &lt;code&gt;EventConsumer&lt;/code&gt; &lt;code&gt;consumer-1&lt;/code&gt; connects to  the &lt;code&gt;source1.foobar.com:8443&lt;/code&gt; URL to consume events. Note, though, that &lt;code&gt;consumer-2&lt;/code&gt; is connecting to another URL.&lt;/p&gt; &lt;p&gt;The central &lt;code&gt;ConfigMap&lt;/code&gt; in &lt;code&gt;eventconsumer-config&lt;/code&gt; contains the buffer size as well as the private key. These will be used by the event consumer controllers unless there are overrides in local &lt;code&gt;ConfigMap&lt;/code&gt;s or in the custom resources.&lt;/p&gt; &lt;p&gt;In the &lt;code&gt;user-ns-1&lt;/code&gt; namespace, a local &lt;code&gt;ConfigMap&lt;/code&gt; overrides the buffer size for the &lt;code&gt;EventConsumer&lt;/code&gt; in that namespace. No local &lt;code&gt;ConfigMap&lt;/code&gt; exists for &lt;code&gt;consumer-2&lt;/code&gt; and no buffer size override exists in the custom resource, so the default buffer size in the central &lt;code&gt;ConfigMap&lt;/code&gt; will be used for that consumer.&lt;/p&gt; &lt;p&gt;In the &lt;code&gt;consumer-2&lt;/code&gt; custom resource, there’s a &lt;code&gt;privateKey&lt;/code&gt; defined, so the one in the central &lt;code&gt;ConfigMap&lt;/code&gt; is not used.&lt;/p&gt; &lt;h2&gt;Notes about the pattern&lt;/h2&gt; &lt;p&gt;This pattern helps with sharing common information for custom resources. The buffer size or the private key could have been hardcoded in the application. Instead, in this case, even the defaults are configurable.&lt;/p&gt; &lt;p&gt;As explained in the &lt;a href="#advanced_2"&gt;Configuration with central and namespaced ConfigMaps&lt;/a&gt; pattern, a better approach could be creating a separate central configuration custom resource that is cluster-scoped and that contains the shared configuration. That might then additionally bring the namespaced configuration custom resources, and so on. If there are many options and if they are complex to build and validate, using a separate custom resource might be better than using a central configuration custom resource, because it can leverage the OpenAPI validation in Kubernetes.&lt;/p&gt; &lt;h2&gt;&lt;a name="advanced_5"&gt;&lt;/a&gt;References to ConfigMaps in custom resources&lt;/h2&gt; &lt;p&gt;The previous pattern, &lt;a href="#advanced_4"&gt;Configuration with custom resources, falling back to ConfigMaps&lt;/a&gt;, helps with sharing the configuration for multiple custom resources. But it does not allow you to specify different shared configurations for custom resources in the same namespace.&lt;/p&gt; &lt;p&gt;We can remedy that issue with this pattern, which keeps the long and complicated configurations in the &lt;code&gt;ConfigMap&lt;/code&gt;s, as shown in Figures 7 and 8. Storing the configurations in a custom resource specification is not desirable.&lt;/p&gt; &lt;div id="attachment_825197" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_5_a.png"&gt;&lt;img aria-describedby="caption-attachment-825197" class="wp-image-825197" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_5_a.png" alt="In this Kubernetes controller pattern, custom resources refer to a ConfigMap for part of their configuration." width="640" height="470" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_5_a.png 929w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_5_a-300x220.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_5_a-768x564.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-825197" class="wp-caption-text"&gt;Figure 7: Custom resources refer to a ConfigMap for part of their configuration.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 8 shows the application landscape created by the controller for the configuration given in the above figure.&lt;/p&gt; &lt;div id="attachment_825207" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_5_b.png"&gt;&lt;img aria-describedby="caption-attachment-825207" class="wp-image-825207" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_5_b.png" alt="In this Kubernetes controller pattern, the controller creates the application landscape based on the custom resources that refer to a ConfigMap." width="640" height="389" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_5_b.png 929w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_5_b-300x182.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/advanced_5_b-768x467.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-825207" class="wp-caption-text"&gt;Figure 8: The controller uses custom resources referring to a ConfigMap to create the application landscape.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Here is the &lt;code&gt;Deployment&lt;/code&gt; that sets up the configurations, starting with the custom resource definition:&lt;/p&gt; &lt;pre&gt;apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: name: eventconsumers.example.com spec: group: example.com versions: - name: v1 ... scope: Namespaced names: plural: eventconsumers singular: eventconsumer kind: EventConsumer ... --- apiVersion: example.com/v1 kind: EventConsumer metadata: name: consumer-1-a spec: source: source1a.foobar.com:443 connectionConfig: ref: throttled --- apiVersion: example.com/v1 kind: EventConsumer metadata: name: consumer-1-b spec: source: source1b.foobar.com:443 connectionConfig: ref: throttled --- apiVersion: example.com/v1 kind: EventConsumer metadata: name: consumer-2 spec: source: source2.foobar.com:443 connectionConfig: ref: unlimited &lt;/pre&gt; &lt;p&gt;And here is the &lt;code&gt;ConfigMap&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: ConfigMap metadata: name: throttled data: lotsOfConfig: here --- apiVersion: v1 kind: ConfigMap metadata: name: unlimited data: otherTypeOfConfig: here &lt;/pre&gt; &lt;p&gt;In this pattern, the custom resource contains a reference to the &lt;code&gt;ConfigMap&lt;/code&gt;. The &lt;code&gt;ConfigMap&lt;/code&gt; can be referenced in multiple custom resources in the same namespace. It is also possible to reference different &lt;code&gt;ConfigMap&lt;/code&gt;s in custom resources that are in the same namespace.&lt;/p&gt; &lt;p&gt;Furthermore, the configuration in the &lt;code&gt;ConfigMap&lt;/code&gt; can even be referenced in custom resources of different types. For example, the TLS settings could be kept in a &lt;code&gt;ConfigMap&lt;/code&gt; and referenced in both a Kafka client component custom resource and a CouchDB client component custom resource.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Patterns in the &lt;a target="_blank" rel="nofollow" href="/blog/2021/04/28/kubernetes-configuration-patterns-part-1-patterns-for-kubernetes-primitives/"&gt;first article&lt;/a&gt; and this one complete this article series on Kubernetes configuration patterns. I personally have seen more configuration patterns used in Kubernetes controllers in the projects I work on, sometimes even very strange ones. The handpicked patterns in this article are the best I&amp;#8217;ve found. They are flexible enough to let you build on top of them to solve your configuration problems.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F05%2Fkubernetes-configuration-patterns-part-2-patterns-for-kubernetes-controllers%2F&amp;#38;linkname=Kubernetes%20configuration%20patterns%2C%20Part%202%3A%20Patterns%20for%20Kubernetes%20controllers" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F05%2Fkubernetes-configuration-patterns-part-2-patterns-for-kubernetes-controllers%2F&amp;#38;linkname=Kubernetes%20configuration%20patterns%2C%20Part%202%3A%20Patterns%20for%20Kubernetes%20controllers" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F05%2Fkubernetes-configuration-patterns-part-2-patterns-for-kubernetes-controllers%2F&amp;#38;linkname=Kubernetes%20configuration%20patterns%2C%20Part%202%3A%20Patterns%20for%20Kubernetes%20controllers" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F05%2Fkubernetes-configuration-patterns-part-2-patterns-for-kubernetes-controllers%2F&amp;#38;linkname=Kubernetes%20configuration%20patterns%2C%20Part%202%3A%20Patterns%20for%20Kubernetes%20controllers" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F05%2Fkubernetes-configuration-patterns-part-2-patterns-for-kubernetes-controllers%2F&amp;#38;linkname=Kubernetes%20configuration%20patterns%2C%20Part%202%3A%20Patterns%20for%20Kubernetes%20controllers" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F05%2Fkubernetes-configuration-patterns-part-2-patterns-for-kubernetes-controllers%2F&amp;#38;linkname=Kubernetes%20configuration%20patterns%2C%20Part%202%3A%20Patterns%20for%20Kubernetes%20controllers" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F05%2Fkubernetes-configuration-patterns-part-2-patterns-for-kubernetes-controllers%2F&amp;#38;linkname=Kubernetes%20configuration%20patterns%2C%20Part%202%3A%20Patterns%20for%20Kubernetes%20controllers" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F05%2Fkubernetes-configuration-patterns-part-2-patterns-for-kubernetes-controllers%2F&amp;#038;title=Kubernetes%20configuration%20patterns%2C%20Part%202%3A%20Patterns%20for%20Kubernetes%20controllers" data-a2a-url="https://developers.redhat.com/blog/2021/05/05/kubernetes-configuration-patterns-part-2-patterns-for-kubernetes-controllers/" data-a2a-title="Kubernetes configuration patterns, Part 2: Patterns for Kubernetes controllers"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/05/kubernetes-configuration-patterns-part-2-patterns-for-kubernetes-controllers/"&gt;Kubernetes configuration patterns, Part 2: Patterns for Kubernetes controllers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/BdmUqPDxuj4" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This article is the second in a two-part article series on Kubernetes configuration patterns, which you can use to configure your Kubernetes applications and controllers. The first article introduced patterns and antipatterns that use only Kubernetes primitives. Those simple patterns are applicable to any application. This second article describes more advanced patterns that require coding [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/05/kubernetes-configuration-patterns-part-2-patterns-for-kubernetes-controllers/"&gt;Kubernetes configuration patterns, Part 2: Patterns for Kubernetes controllers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/05/05/kubernetes-configuration-patterns-part-2-patterns-for-kubernetes-controllers/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">825297</post-id><dc:creator>Ali Ok</dc:creator><dc:date>2021-05-05T07:00:59Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/05/05/kubernetes-configuration-patterns-part-2-patterns-for-kubernetes-controllers/</feedburner:origLink></entry></feed>
